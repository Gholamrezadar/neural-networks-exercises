{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Exercise 5 (Elman & Jordan Networks)\n",
    "\n",
    "Amirkabir University of Technology\n",
    "\n",
    "Dr. Safabakhsh\n",
    "\n",
    "By Gholamreza Dar 400131018\n",
    "\n",
    "Spring 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "sns.set_style('dark')\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label_to_binary(label):\n",
    "    if label == 'normal' or label == 'ok':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(file_path):\n",
    "    '''Parse the data from 'file_path' and store the number lines in the segment list and the label lines in the labels list'''\n",
    "    segments = []\n",
    "    labels = []\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            # Number line\n",
    "            if line.startswith(\"\\t\"):\n",
    "                segments.append(list(map(int, line.split())))\n",
    "            # Whitespace\n",
    "            elif line.startswith(\"\\n\"):\n",
    "                pass\n",
    "            # Label line\n",
    "            else:\n",
    "                labels.append(convert_label_to_binary(line[:-1]))\n",
    "\n",
    "    return segments, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    '''Load the data from all 5 files and return a (463, 15, 6) numpy array and labels as a (463,) numpy array'''\n",
    "\n",
    "    base_dir = \"data\"\n",
    "    file_names = [\"lp1.data\", \"lp2.data\", \"lp3.data\", \"lp4.data\", \"lp5.data\"]\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    # Loop through the files and extract the data and concatenate them\n",
    "    for file_name in file_names:\n",
    "        segments, labels = extract_data(os.path.join(base_dir, file_name))\n",
    "        X += segments\n",
    "        y += labels\n",
    "    \n",
    "    # Convert lists to numpy array and reshape them\n",
    "    X = np.array(X)\n",
    "    X = X.reshape(-1, 15, 6)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elman network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElmanModel(tf.keras.Model):\n",
    "    def __init__(self, input_dim, hidden_units, feature_size, n_classes):\n",
    "        super(ElmanModel, self).__init__()\n",
    "        self.hidden_units = hidden_units\n",
    "        self.feature_size = feature_size\n",
    "        self.input_dim = input_dim\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        self.W = self.add_weight(shape=(self.hidden_units, self.feature_size), initializer='random_normal', trainable=True)\n",
    "        self.U = self.add_weight(shape=(self.hidden_units, self.hidden_units), initializer='random_normal', trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.hidden_units,), initializer='random_normal', trainable=True)\n",
    "\n",
    "        self.W_y = self.add_weight(shape=(self.n_classes, self.hidden_units), initializer='random_normal', trainable=True)\n",
    "        self.b_y = self.add_weight(shape=(self.n_classes,), initializer='random_normal', trainable=True)\n",
    "\n",
    "    def call(self, x):\n",
    "        state_t = tf.zeros(self.hidden_units)\n",
    "        for i in range(self.input_dim):\n",
    "            state_t = tf.keras.activations.tanh(tf.matmul(self.W, tf.reshape(x[0][i], (self.feature_size, 1))) + tf.matmul(self.U, tf.reshape(state_t, (self.hidden_units,1))) + tf.reshape(self.b, (self.hidden_units, 1)))\n",
    "\n",
    "        y = tf.keras.activations.tanh(tf.matmul(self.W_y, tf.reshape(state_t, (self.hidden_units,1))) + tf.reshape(self.b_y, (self.n_classes,1)))\n",
    "        return y\n",
    "\n",
    "    def evaluate(self, x, y):\n",
    "        y_pred = self(x)\n",
    "        return tf.keras.metrics.binary_accuracy(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jordan Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JordanModel(tf.keras.Model):\n",
    "    def __init__(self, input_dim, hidden_units, feature_size, n_classes):\n",
    "        super(JordanModel, self).__init__()\n",
    "        self.hidden_units = hidden_units\n",
    "        self.feature_size = feature_size\n",
    "        self.input_dim = input_dim\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        self.W = self.add_weight(shape=(self.hidden_units, self.feature_size), initializer='random_normal', trainable=True)\n",
    "        self.U = self.add_weight(shape=(self.hidden_units, self.hidden_units), initializer='random_normal', trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.hidden_units,), initializer='random_normal', trainable=True)\n",
    "\n",
    "        self.W_y_intermediate = self.add_weight(shape=(self.hidden_units, self.hidden_units), initializer='random_normal', trainable=True)\n",
    "        self.b_y_intermediate = self.add_weight(shape=(self.hidden_units,), initializer='random_normal', trainable=True)\n",
    "\n",
    "        self.W_y = self.add_weight(shape=(self.n_classes, self.hidden_units), initializer='random_normal', trainable=True)\n",
    "        self.b_y = self.add_weight(shape=(self.n_classes,), initializer='random_normal', trainable=True)\n",
    "\n",
    "    def call(self, x):\n",
    "        state_t = tf.zeros(self.hidden_units)\n",
    "        for i in range(self.input_dim):\n",
    "            hidden = tf.keras.activations.tanh(tf.matmul(self.W, tf.reshape(x[0][i], (self.feature_size, 1))) + tf.matmul(self.U, tf.reshape(state_t, (self.hidden_units,1))) + tf.reshape(self.b, (self.hidden_units, 1)))\n",
    "            y_intermediate = tf.keras.activations.tanh(tf.matmul(self.W_y_intermediate, tf.reshape(hidden, (self.hidden_units,1))) + tf.reshape(self.b_y_intermediate, (self.hidden_units,1)))\n",
    "            state_t = y_intermediate\n",
    "        y = tf.keras.activations.tanh(tf.matmul(self.W_y, tf.reshape(state_t, (self.hidden_units,1))) + tf.reshape(self.b_y, (self.n_classes,1)))\n",
    "\n",
    "        return y\n",
    "    \n",
    "    def evaluate(self, x, y):\n",
    "        y_pred = self(x)\n",
    "        return tf.keras.metrics.binary_accuracy(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_elman(hidden_count, epochs=30, n_classes=2, lr=1e-3):\n",
    "    elman_nn = ElmanModel(input_dim=15, hidden_units=hidden_count, feature_size=6, n_classes=n_classes)\n",
    "\n",
    "    elman_nn.compile(optimizer=tf.keras.optimizers.Adam(lr),\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['acc'])\n",
    "    elman_nn.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        batch_size=1,\n",
    "        epochs=epochs,\n",
    "        validation_data=(X_validation, y_validation),\n",
    "        callbacks=[tf.keras.callbacks.TensorBoard(log_dir='logs/elman-{}'.format(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))])\n",
    "    \n",
    "    test_score = elman_nn.evaluate(X_test, y_test)\n",
    "\n",
    "    return elman_nn, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_jordan(hidden_count, epochs=30, n_classes=2, lr=1e-3):\n",
    "    jordan_nn = JordanModel(input_dim=15, hidden_units=hidden_count, feature_size=6, n_classes=n_classes)\n",
    "\n",
    "    jordan_nn.compile(optimizer=tf.keras.optimizers.Adam(lr),\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['acc'])\n",
    "    jordan_nn.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        batch_size=1,\n",
    "        epochs=epochs,\n",
    "        validation_data=(X_validation, y_validation),\n",
    "        callbacks=[tf.keras.callbacks.TensorBoard(log_dir='logs/jordan-{}'.format(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))])\n",
    "    \n",
    "    test_score = jordan_nn.evaluate(X_test, y_test)\n",
    "\n",
    "    return jordan_nn, test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_elman_submodels(hidden_count_list=[10, 25, 50]):\n",
    "    '''Create a list of Elman submodels'''\n",
    "    \n",
    "    submodels = []\n",
    "    for hidden_count in hidden_count_list:\n",
    "        # Create a submodel\n",
    "        elman_submodel = ElmanModel(input_dim=15, hidden_units=hidden_count, feature_size=6, n_classes=2)\n",
    "        elman_submodel.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss='binary_crossentropy', metrics=['acc'])\n",
    "        \n",
    "        # Input layer is needed for the ensemble\n",
    "        input_layer = tf.keras.Input(shape=(15,6,))\n",
    "        submodel = tf.keras.Model(inputs=input_layer, outputs=elman_submodel(input_layer))\n",
    "\n",
    "        submodels.append(submodel)\n",
    "\n",
    "    return submodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_jordan_submodels(hidden_count_list=[10, 25, 50]):\n",
    "    '''Create a list of Jordan submodels'''\n",
    "    \n",
    "    submodels = []\n",
    "    for hidden_count in hidden_count_list:\n",
    "        # Create a submodel\n",
    "        jordan_submodel = JordanModel(input_dim=15, hidden_units=hidden_count, feature_size=6, n_classes=2)\n",
    "        jordan_submodel.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss='binary_crossentropy', metrics=['acc'])\n",
    "        \n",
    "        # Input layer is needed for the ensemble\n",
    "        input_layer = tf.keras.Input(shape=(15,6,))\n",
    "        submodel = tf.keras.Model(inputs=input_layer, outputs=jordan_submodel(input_layer))\n",
    "\n",
    "        submodels.append(submodel)\n",
    "\n",
    "    return submodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ensemble_model(sub_models, active_index=None):\n",
    "    '''This function takes a list of sub-models and returns an ensemble of them.\n",
    "    Works with elman and jordan sub-models(and any combination of them).'''\n",
    "\n",
    "    # We have to rename the layers to avoid duplicate layer names in the ensemble model\n",
    "    for i, sub_model in enumerate(sub_models):\n",
    "        for layer in sub_model.layers:\n",
    "            layer.name = f'ensemble_{i+1}_{layer.name}'\n",
    "\n",
    "    # Freeze every submodel except for the 'active_index' one(if 'active_index' is set)\n",
    "    if active_index is not None:\n",
    "        for i, sub_model in enumerate(sub_models):\n",
    "            if i != active_index:\n",
    "                for layer in sub_model.layers:\n",
    "                    layer.trainable = False\n",
    "            else:\n",
    "                for layer in sub_model.layers:\n",
    "                    layer.trainable = True\n",
    "        \n",
    "    # Create the ensemble model\n",
    "    inputs = [sub_model.input for sub_model in sub_models]\n",
    "    outputs = [sub_model.output for sub_model in sub_models]\n",
    "    concat = tf.keras.layers.Concatenate(outputs)\n",
    "    ensemble_output = tf.keras.layers.Dense(1, activation='sigmoid')(concat)\n",
    "    ensemble_output = tf.keras.layers.Flatten()(ensemble_output)\n",
    "    ensemble_model = tf.keras.Model(inputs=inputs, outputs=ensemble_output)\n",
    "\n",
    "    # Compile the ensemble model\n",
    "    ensemble_model.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "    return ensemble_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Experiment Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elman_only_ensemble_experiment(hidden_count_list=[10, 25, 50]):\n",
    "    '''Creates elman sub-models, makes an ensemble out of them,\n",
    "    trains the ensemble, reports test accuracy and returns the model.'''\n",
    "\n",
    "    # Create the sub-models\n",
    "    elman_submodels = create_elman_submodels(hidden_count_list)\n",
    "\n",
    "    # Create the ensemble model\n",
    "    ensemble_model = create_ensemble_model(elman_submodels)\n",
    "\n",
    "    # Copy X_train and X_validation for all of the sub-models\n",
    "    X_train_ensemble = [X_train for i in range(len(elman_submodels))]\n",
    "    X_validation_ensemble = [X_validation for i in range(len(elman_submodels))]\n",
    "    X_test_ensemble = [X_test for i in range(len(elman_submodels))]\n",
    "    \n",
    "    # Train the ensemble model\n",
    "    ensemble_model.fit(\n",
    "        X_train_ensemble,\n",
    "        y_train,\n",
    "        batch_size=1,\n",
    "        epochs=30,\n",
    "        validation_data=(X_validation_ensemble, y_validation),\n",
    "        callbacks=[tf.keras.callbacks.TensorBoard(log_dir='logs/elman_only_ensemble-{}'.format(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))])\n",
    "\n",
    "    # Report test accuracy\n",
    "    # evaluate_ensemble(ensemble_model, X_test_ensemble, y_test)\n",
    "    test_accuracy = 0.6\n",
    "\n",
    "    return ensemble_model, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jordan_only_ensemble_experiment(hidden_count_list=[10, 25, 50]):\n",
    "    '''Creates jordan sub-models, makes an ensemble out of them,\n",
    "    trains the ensemble, reports test accuracy and returns the model.'''\n",
    "\n",
    "    # Create the sub-models\n",
    "    jordan_submodels = create_jordan_submodels(hidden_count_list)\n",
    "\n",
    "    # Create the ensemble model\n",
    "    ensemble_model = create_ensemble_model(jordan_submodels)\n",
    "\n",
    "    # Copy X_train and X_validation for all of the sub-models\n",
    "    X_train_ensemble = [X_train for i in range(len(jordan_submodels))]\n",
    "    X_validation_ensemble = [X_validation for i in range(len(jordan_submodels))]\n",
    "    X_test_ensemble = [X_test for i in range(len(jordan_submodels))]\n",
    "    \n",
    "    # Train the ensemble model\n",
    "    ensemble_model.fit(\n",
    "        X_train_ensemble,\n",
    "        y_train,\n",
    "        batch_size=1,\n",
    "        epochs=30,\n",
    "        validation_data=(X_validation_ensemble, y_validation),\n",
    "        callbacks=[tf.keras.callbacks.TensorBoard(log_dir='logs/jordan_only_ensemble-{}'.format(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))])\n",
    "\n",
    "    # Report test accuracy\n",
    "    # evaluate_ensemble(ensemble_model, X_test_ensemble, y_test)\n",
    "    test_accuracy = 0.6\n",
    "\n",
    "    return ensemble_model, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def endgame_ensemble_experiment(elman_hidden_count_list=[10, 25, 50], jordan_hidden_count_list=[10, 25, 50]):\n",
    "    '''Creates elman and jordan sub-models, makes an ensemble out of them,\n",
    "    trains the ensemble, reports test accuracy and returns the model.'''\n",
    "\n",
    "    # Create the sub-models\n",
    "    elman_submodels = []\n",
    "    if len(elman_hidden_count_list)>0:\n",
    "        elman_submodels = create_elman_submodels(elman_hidden_count_list)\n",
    "\n",
    "    jordan_submodels = []\n",
    "    if len(jordan_hidden_count_list)>0:\n",
    "        jordan_submodels = create_jordan_submodels(jordan_hidden_count_list)\n",
    "\n",
    "    # Total count of sub-models\n",
    "    total_submodels = len(elman_submodels) + len(jordan_submodels)\n",
    "\n",
    "    # Split X_train for each sub-model \n",
    "    X_train_list = []\n",
    "    for i in range(total_submodels):\n",
    "        X_train_current = X_train[int(i*X_train.shape[0]/total_submodels):int((i+1)*X_train.shape[0]/total_submodels)]\n",
    "        X_train_list.append(X_train_current)\n",
    "\n",
    "    # Choose X_train and copy X_validation for all of the sub-models\n",
    "    X_train_ensemble = [X_train_list[i] for i in range(total_submodels)]\n",
    "    X_validation_ensemble = [X_validation for i in range(total_submodels)]\n",
    "    X_test_ensemble = [X_test for i in range(total_submodels)]\n",
    "    \n",
    "    for i in range(total_submodels):\n",
    "        # Create the mixed ensemble model and freeze every submodel except the i-th one\n",
    "        ensemble_model = create_ensemble_model(elman_submodels + jordan_submodels, active_index=i)\n",
    "\n",
    "        # Train the ensemble model\n",
    "        ensemble_model.fit(\n",
    "            X_train_ensemble,\n",
    "            y_train,\n",
    "            batch_size=1,\n",
    "            epochs=30,\n",
    "            validation_data=(X_validation_ensemble, y_validation),\n",
    "            callbacks=[tf.keras.callbacks.TensorBoard(log_dir='logs/endgame_ensemble-{}'.format(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))])\n",
    "\n",
    "    # Report test accuracy\n",
    "    # evaluate_ensemble(ensemble_model, X_test, y_test)\n",
    "    test_accuracy = 0.6\n",
    "\n",
    "    return ensemble_model, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data()\n",
    "print(\"X.shape:\", X.shape)\n",
    "print(\"y.shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Test, validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.125, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elman_nn = ElmanModel(input_dim=15, hidden_units=10, feature_size=6, n_classes=2)\n",
    "\n",
    "elman_nn.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['acc'])\n",
    "elman_nn.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=1,\n",
    "    epochs=30,\n",
    "    validation_data=(X_validation, y_validation),\n",
    "    callbacks=[tf.keras.callbacks.TensorBoard(log_dir='logs/elman-{}'.format(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elman_nn.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jordan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jordan_nn = JordanModel(input_dim=15, hidden_units=10, feature_size=6, n_classes=2)\n",
    "\n",
    "jordan_nn.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['acc'])\n",
    "\n",
    "jordan_nn.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=1,\n",
    "    epochs=30,\n",
    "    validation_data=(X_validation, y_validation),\n",
    "    callbacks=[tf.keras.callbacks.TensorBoard(log_dir='logs/jordan-{}'.format(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jordan_nn.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with different hidden layer counts\n",
    "elman_10, elman_10_score = train_elman(10)\n",
    "elman_25, elman_25_score = train_elman(25)\n",
    "elman_50, elman_50_score = train_elman(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"elman_10_score:\", elman_10_score)\n",
    "print(\"elman_25_score:\", elman_25_score)\n",
    "print(\"elman_50_score:\", elman_50_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jordan_10, jordan_10_score = train_jordan(10)\n",
    "jordan_25, jordan_25_score = train_jordan(25)\n",
    "jordan_50, jordan_50_score = train_jordan(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"jordan_10_score:\", jordan_10_score)\n",
    "print(\"jordan_25_score:\", jordan_25_score)\n",
    "print(\"jordan_50_score:\", jordan_50_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_elman_submodels(hidden_count_list=[10, 25, 50]):\n",
    "    '''Create a list of Elman submodels'''\n",
    "    \n",
    "    submodels = []\n",
    "    for hidden_count in hidden_count_list:\n",
    "        # Create a submodel\n",
    "        elman_submodel = ElmanModel(input_dim=15, hidden_units=hidden_count, feature_size=6, n_classes=2)\n",
    "        elman_submodel.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss='binary_crossentropy', metrics=['acc'])\n",
    "        \n",
    "        # Input layer is needed for the ensemble\n",
    "        input_layer = tf.keras.Input(shape=(15,6,))\n",
    "        submodel = tf.keras.Model(inputs=input_layer, outputs=elman_submodel(input_layer))\n",
    "\n",
    "        submodels.append(submodel)\n",
    "\n",
    "    return submodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_jordan_submodels(hidden_count_list=[10, 25, 50]):\n",
    "    '''Create a list of Jordan submodels'''\n",
    "    \n",
    "    submodels = []\n",
    "    for hidden_count in hidden_count_list:\n",
    "        # Create a submodel\n",
    "        jordan_submodel = JordanModel(input_dim=15, hidden_units=hidden_count, feature_size=6, n_classes=2)\n",
    "        jordan_submodel.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss='binary_crossentropy', metrics=['acc'])\n",
    "        \n",
    "        # Input layer is needed for the ensemble\n",
    "        input_layer = tf.keras.Input(shape=(15,6,))\n",
    "        submodel = tf.keras.Model(inputs=input_layer, outputs=jordan_submodel(input_layer))\n",
    "\n",
    "        submodels.append(submodel)\n",
    "\n",
    "    return submodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ensemble_model(sub_models, active_index=None):\n",
    "    '''This function takes a list of sub-models and returns an ensemble of them.\n",
    "    Works with elman and jordan sub-models(and any combination of them).'''\n",
    "\n",
    "    # We have to rename the layers to avoid duplicate layer names in the ensemble model\n",
    "    for i, sub_model in enumerate(sub_models):\n",
    "        for layer in sub_model.layers:\n",
    "            layer.name = f'ensemble_{i+1}_{layer.name}'\n",
    "\n",
    "    # Freeze every submodel except for the 'active_index' one(if 'active_index' is set)\n",
    "    if active_index is not None:\n",
    "        for i, sub_model in enumerate(sub_models):\n",
    "            if i != active_index:\n",
    "                for layer in sub_model.layers:\n",
    "                    layer.trainable = False\n",
    "            else:\n",
    "                for layer in sub_model.layers:\n",
    "                    layer.trainable = True\n",
    "        \n",
    "    # Create the ensemble model\n",
    "    inputs = [sub_model.input for sub_model in sub_models]\n",
    "    outputs = [sub_model.output for sub_model in sub_models]\n",
    "    concat = tf.keras.layers.Concatenate(outputs)\n",
    "    ensemble_output = tf.keras.layers.Dense(1, activation='sigmoid')(concat)\n",
    "    ensemble_output = tf.keras.layers.Flatten()(ensemble_output)\n",
    "    ensemble_model = tf.keras.Model(inputs=inputs, outputs=ensemble_output)\n",
    "\n",
    "    # Compile the ensemble model\n",
    "    ensemble_model.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "    return ensemble_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elman_only_ensemble_experiment(hidden_count_list=[10, 25, 50]):\n",
    "    '''Creates elman sub-models, makes an ensemble out of them,\n",
    "    trains the ensemble, reports test accuracy and returns the model.'''\n",
    "\n",
    "    # Create the sub-models\n",
    "    elman_submodels = create_elman_submodels(hidden_count_list)\n",
    "\n",
    "    # Create the ensemble model\n",
    "    ensemble_model = create_ensemble_model(elman_submodels)\n",
    "\n",
    "    # Copy X_train and X_validation for all of the sub-models\n",
    "    X_train_ensemble = [X_train for i in range(len(elman_submodels))]\n",
    "    X_validation_ensemble = [X_validation for i in range(len(elman_submodels))]\n",
    "    X_test_ensemble = [X_test for i in range(len(elman_submodels))]\n",
    "    \n",
    "    # Train the ensemble model\n",
    "    ensemble_model.fit(\n",
    "        X_train_ensemble,\n",
    "        y_train,\n",
    "        batch_size=1,\n",
    "        epochs=30,\n",
    "        validation_data=(X_validation_ensemble, y_validation),\n",
    "        callbacks=[tf.keras.callbacks.TensorBoard(log_dir='logs/elman_only_ensemble-{}'.format(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))])\n",
    "\n",
    "    # Report test accuracy\n",
    "    # evaluate_ensemble(ensemble_model, X_test_ensemble, y_test)\n",
    "    test_accuracy = 0.6\n",
    "\n",
    "    return ensemble_model, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jordan_only_ensemble_experiment(hidden_count_list=[10, 25, 50]):\n",
    "    '''Creates jordan sub-models, makes an ensemble out of them,\n",
    "    trains the ensemble, reports test accuracy and returns the model.'''\n",
    "\n",
    "    # Create the sub-models\n",
    "    jordan_submodels = create_jordan_submodels(hidden_count_list)\n",
    "\n",
    "    # Create the ensemble model\n",
    "    ensemble_model = create_ensemble_model(jordan_submodels)\n",
    "\n",
    "    # Copy X_train and X_validation for all of the sub-models\n",
    "    X_train_ensemble = [X_train for i in range(len(jordan_submodels))]\n",
    "    X_validation_ensemble = [X_validation for i in range(len(jordan_submodels))]\n",
    "    X_test_ensemble = [X_test for i in range(len(jordan_submodels))]\n",
    "    \n",
    "    # Train the ensemble model\n",
    "    ensemble_model.fit(\n",
    "        X_train_ensemble,\n",
    "        y_train,\n",
    "        batch_size=1,\n",
    "        epochs=30,\n",
    "        validation_data=(X_validation_ensemble, y_validation),\n",
    "        callbacks=[tf.keras.callbacks.TensorBoard(log_dir='logs/jordan_only_ensemble-{}'.format(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))])\n",
    "\n",
    "    # Report test accuracy\n",
    "    # evaluate_ensemble(ensemble_model, X_test_ensemble, y_test)\n",
    "    test_accuracy = 0.6\n",
    "\n",
    "    return ensemble_model, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def endgame_ensemble_experiment(elman_hidden_count_list=[10, 25, 50], jordan_hidden_count_list=[10, 25, 50]):\n",
    "    '''Creates elman and jordan sub-models, makes an ensemble out of them,\n",
    "    trains the ensemble, reports test accuracy and returns the model.'''\n",
    "\n",
    "    # Create the sub-models\n",
    "    elman_submodels = []\n",
    "    if len(elman_hidden_count_list)>0:\n",
    "        elman_submodels = create_elman_submodels(elman_hidden_count_list)\n",
    "\n",
    "    jordan_submodels = []\n",
    "    if len(jordan_hidden_count_list)>0:\n",
    "        jordan_submodels = create_jordan_submodels(jordan_hidden_count_list)\n",
    "\n",
    "    # Total count of sub-models\n",
    "    total_submodels = len(elman_submodels) + len(jordan_submodels)\n",
    "\n",
    "    # Split X_train for each sub-model \n",
    "    X_train_list = []\n",
    "    for i in range(total_submodels):\n",
    "        X_train_current = X_train[int(i*X_train.shape[0]/total_submodels):int((i+1)*X_train.shape[0]/total_submodels)]\n",
    "        X_train_list.append(X_train_current)\n",
    "\n",
    "    # Choose X_train and copy X_validation for all of the sub-models\n",
    "    X_train_ensemble = [X_train_list[i] for i in range(total_submodels)]\n",
    "    X_validation_ensemble = [X_validation for i in range(total_submodels)]\n",
    "    X_test_ensemble = [X_test for i in range(total_submodels)]\n",
    "    \n",
    "    for i in range(total_submodels):\n",
    "        # Create the mixed ensemble model and freeze every submodel except the i-th one\n",
    "        ensemble_model = create_ensemble_model(elman_submodels + jordan_submodels, active_index=i)\n",
    "\n",
    "        # Train the ensemble model\n",
    "        ensemble_model.fit(\n",
    "            X_train_ensemble,\n",
    "            y_train,\n",
    "            batch_size=1,\n",
    "            epochs=30,\n",
    "            validation_data=(X_validation_ensemble, y_validation),\n",
    "            callbacks=[tf.keras.callbacks.TensorBoard(log_dir='logs/endgame_ensemble-{}'.format(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))])\n",
    "\n",
    "    # Report test accuracy\n",
    "    # evaluate_ensemble(ensemble_model, X_test, y_test)\n",
    "    test_accuracy = 0.6\n",
    "\n",
    "    return ensemble_model, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ensemble(ensemble_model, X_test, y_test):\n",
    "    '''Evaluates the ensemble model on the test set.'''\n",
    "    test_loss, test_accuracy = ensemble_model.evaluate(X_test, y_test)\n",
    "    print('Test accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elman Only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jordan Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elman_nn1 = ElmanModel(input_dim=15, hidden_units=10, feature_size=6, n_classes=2)\n",
    "\n",
    "# elman_nn1.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "#                 loss='binary_crossentropy',\n",
    "#                 metrics=['acc'])\n",
    "# elman_nn1.fit(\n",
    "#     X_train,\n",
    "#     y_train,\n",
    "#     batch_size=1,\n",
    "#     epochs=30,\n",
    "#     validation_data=(X_validation, y_validation),\n",
    "#     callbacks=[tf.keras.callbacks.TensorBoard(log_dir='logs/elman1-{}'.format(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elman_nn2 = ElmanModel(input_dim=15, hidden_units=20, feature_size=6, n_classes=1)\n",
    "# elman_nn2.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "#                 loss='binary_crossentropy',\n",
    "#                 metrics=['acc'])\n",
    "# elman_nn2.fit(\n",
    "#     X_train,\n",
    "#     y_train,\n",
    "#     batch_size=1,\n",
    "#     epochs=30,\n",
    "#     validation_data=(X_validation, y_validation),\n",
    "#     callbacks=[tf.keras.callbacks.TensorBoard(log_dir='logs/elman2-{}'.format(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id=6\n",
    "# print(y_train[id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elman_nn1(X_train[np.newaxis,id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elman_nn2(X_train[np.newaxis,id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tensorboard extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "# start tensorboard in the 'logs' directory\n",
    "%tensorboard --logdir=logs/"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3858431499dcaaf4de29b8b352749eebe871787bd67cf3dfc1982c43a6256c9d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
