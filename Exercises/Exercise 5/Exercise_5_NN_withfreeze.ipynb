{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Exercise 5 (Elman & Jordan Networks)\n",
    "\n",
    "Amirkabir University of Technology\n",
    "\n",
    "Dr. Safabakhsh\n",
    "\n",
    "By Gholamreza Dar 400131018\n",
    "\n",
    "Spring 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label_to_binary(label):\n",
    "    if label == 'normal' or label == 'ok':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(file_path):\n",
    "    '''Parse the data from 'file_path' and store the number lines in the segment list and the label lines in the labels list'''\n",
    "    segments = []\n",
    "    labels = []\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            # Number line\n",
    "            if line.startswith(\"\\t\"):\n",
    "                segments.append(list(map(int, line.split())))\n",
    "            # Whitespace\n",
    "            elif line.startswith(\"\\n\"):\n",
    "                pass\n",
    "            # Label line\n",
    "            else:\n",
    "                labels.append(convert_label_to_binary(line[:-1]))\n",
    "\n",
    "    return segments, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    '''Load the data from all 5 files and return a (463, 15, 6) numpy array and labels as a (463,) numpy array'''\n",
    "\n",
    "    base_dir = \"data\"\n",
    "    file_names = [\"lp1.data\", \"lp2.data\", \"lp3.data\", \"lp4.data\", \"lp5.data\"]\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    # Loop through the files and extract the data and concatenate them\n",
    "    for file_name in file_names:\n",
    "        segments, labels = extract_data(os.path.join(base_dir, file_name))\n",
    "        X += segments\n",
    "        y += labels\n",
    "    \n",
    "    # Convert lists to numpy array and reshape them\n",
    "    X = np.array(X)\n",
    "    X = X.reshape(-1, 15, 6).astype(np.float32)\n",
    "    y = np.array(y).astype(np.float32)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elman network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElmanModel(tf.keras.Model):\n",
    "    def __init__(self, input_dim, hidden_units, feature_size, n_classes):\n",
    "        super(ElmanModel, self).__init__()\n",
    "        self.hidden_units = hidden_units\n",
    "        self.feature_size = feature_size\n",
    "        self.input_dim = input_dim\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        self.W = self.add_weight(shape=(self.hidden_units, self.feature_size), initializer='random_normal', trainable=True)\n",
    "        self.U = self.add_weight(shape=(self.hidden_units, self.hidden_units), initializer='random_normal', trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.hidden_units,), initializer='random_normal', trainable=True)\n",
    "\n",
    "        self.W_y = self.add_weight(shape=(self.n_classes, self.hidden_units), initializer='random_normal', trainable=True)\n",
    "        self.b_y = self.add_weight(shape=(self.n_classes,), initializer='random_normal', trainable=True)\n",
    "\n",
    "    def call(self, x):\n",
    "        state_t = tf.zeros(self.hidden_units)\n",
    "        for i in range(self.input_dim):\n",
    "            state_t = tf.keras.activations.tanh(tf.matmul(self.W, tf.reshape(x[0][i], (self.feature_size, 1))) + tf.matmul(self.U, tf.reshape(state_t, (self.hidden_units,1))) + tf.reshape(self.b, (self.hidden_units, 1)))\n",
    "\n",
    "        y = tf.keras.activations.tanh(tf.matmul(self.W_y, tf.reshape(state_t, (self.hidden_units,1))) + tf.reshape(self.b_y, (self.n_classes,1)))\n",
    "        return y\n",
    "\n",
    "    # def evaluate(self, x, y, **kwargs):\n",
    "    #     y_pred = self(x)\n",
    "    #     return tf.keras.metrics.binary_accuracy(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jordan Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JordanModel(tf.keras.Model):\n",
    "    def __init__(self, input_dim, hidden_units, feature_size, n_classes):\n",
    "        super(JordanModel, self).__init__()\n",
    "        self.hidden_units = hidden_units\n",
    "        self.feature_size = feature_size\n",
    "        self.input_dim = input_dim\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        self.W = self.add_weight(shape=(self.hidden_units, self.feature_size), initializer='random_normal', trainable=True)\n",
    "        self.U = self.add_weight(shape=(self.hidden_units, self.hidden_units), initializer='random_normal', trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.hidden_units,), initializer='random_normal', trainable=True)\n",
    "\n",
    "        self.W_y_intermediate = self.add_weight(shape=(self.hidden_units, self.hidden_units), initializer='random_normal', trainable=True)\n",
    "        self.b_y_intermediate = self.add_weight(shape=(self.hidden_units,), initializer='random_normal', trainable=True)\n",
    "\n",
    "        self.W_y = self.add_weight(shape=(self.n_classes, self.hidden_units), initializer='random_normal', trainable=True)\n",
    "        self.b_y = self.add_weight(shape=(self.n_classes,), initializer='random_normal', trainable=True)\n",
    "\n",
    "    def call(self, x):\n",
    "        state_t = tf.zeros(self.hidden_units)\n",
    "        for i in range(self.input_dim):\n",
    "            hidden = tf.keras.activations.tanh(tf.matmul(self.W, tf.reshape(x[0][i], (self.feature_size, 1))) + tf.matmul(self.U, tf.reshape(state_t, (self.hidden_units,1))) + tf.reshape(self.b, (self.hidden_units, 1)))\n",
    "            y_intermediate = tf.keras.activations.tanh(tf.matmul(self.W_y_intermediate, tf.reshape(hidden, (self.hidden_units,1))) + tf.reshape(self.b_y_intermediate, (self.hidden_units,1)))\n",
    "            state_t = y_intermediate\n",
    "        y = tf.keras.activations.tanh(tf.matmul(self.W_y, tf.reshape(state_t, (self.hidden_units,1))) + tf.reshape(self.b_y, (self.n_classes,1)))\n",
    "\n",
    "        return y\n",
    "    \n",
    "    # def evaluate(self, x, y):\n",
    "    #     y_pred = self(x)\n",
    "    #     return tf.keras.metrics.binary_accuracy(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_elman(hidden_count, epochs=30, n_classes=2, lr=1e-3):\n",
    "    elman_nn = ElmanModel(input_dim=15, hidden_units=hidden_count, feature_size=6, n_classes=n_classes)\n",
    "\n",
    "    elman_nn.compile(optimizer=tf.keras.optimizers.Adam(lr),\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['acc'])\n",
    "    elman_nn.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        batch_size=1,\n",
    "        epochs=epochs,\n",
    "        validation_data=(X_validation, y_validation),\n",
    "        callbacks=[tf.keras.callbacks.TensorBoard(log_dir='logs/elman-{}'.format(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))])\n",
    "    \n",
    "    # test_score = elman_nn.evaluate(X_test, y_test)\n",
    "    test_score = 0.7\n",
    "\n",
    "    return elman_nn, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_jordan(hidden_count, epochs=30, n_classes=2, lr=1e-3):\n",
    "    jordan_nn = JordanModel(input_dim=15, hidden_units=hidden_count, feature_size=6, n_classes=n_classes)\n",
    "\n",
    "    jordan_nn.compile(optimizer=tf.keras.optimizers.Adam(lr),\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['acc'])\n",
    "    jordan_nn.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        batch_size=1,\n",
    "        epochs=epochs,\n",
    "        validation_data=(X_validation, y_validation),\n",
    "        callbacks=[tf.keras.callbacks.TensorBoard(log_dir='logs/jordan-{}'.format(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))])\n",
    "    \n",
    "    # test_score = jordan_nn.evaluate(X_test, y_test)\n",
    "    test_score=0.4\n",
    "\n",
    "    return jordan_nn, test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_elman_submodels(hidden_count_list=[10, 25, 50]):\n",
    "    '''Create a list of Elman submodels'''\n",
    "    \n",
    "    submodels = []\n",
    "    for hidden_count in hidden_count_list:\n",
    "        # Create a submodel\n",
    "        elman_submodel = ElmanModel(input_dim=15, hidden_units=hidden_count, feature_size=6, n_classes=2)\n",
    "        elman_submodel.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss='binary_crossentropy', metrics=['acc'])\n",
    "        \n",
    "        # Input layer is needed for the ensemble\n",
    "        input_layer = tf.keras.Input(shape=(15,6,))\n",
    "        submodel = tf.keras.Model(inputs=input_layer, outputs=elman_submodel(input_layer))\n",
    "\n",
    "        submodels.append(submodel)\n",
    "\n",
    "    return submodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_jordan_submodels(hidden_count_list=[10, 25, 50]):\n",
    "    '''Create a list of Jordan submodels'''\n",
    "    \n",
    "    submodels = []\n",
    "    for hidden_count in hidden_count_list:\n",
    "        # Create a submodel\n",
    "        jordan_submodel = JordanModel(input_dim=15, hidden_units=hidden_count, feature_size=6, n_classes=2)\n",
    "        jordan_submodel.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss='binary_crossentropy', metrics=['acc'])\n",
    "        \n",
    "        # Input layer is needed for the ensemble\n",
    "        input_layer = tf.keras.Input(shape=(15,6,))\n",
    "        submodel = tf.keras.Model(inputs=input_layer, outputs=jordan_submodel(input_layer))\n",
    "\n",
    "        submodels.append(submodel)\n",
    "\n",
    "    return submodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ensemble_model(sub_models, active_index=None):\n",
    "    '''This function takes a list of sub-models and returns an ensemble of them.\n",
    "    Works with elman and jordan sub-models(and any combination of them).'''\n",
    "\n",
    "    # We have to rename the layers to avoid duplicate layer names in the ensemble model\n",
    "    for i, sub_model in enumerate(sub_models):\n",
    "        for layer in sub_model.layers:\n",
    "            layer._name = f'ensemble_{i+1}_{layer.name}'\n",
    "\n",
    "    # Freeze every submodel except for the 'active_index' one(if 'active_index' is set)\n",
    "    if active_index is not None:\n",
    "        for i, sub_model in enumerate(sub_models):\n",
    "            if i != active_index:\n",
    "                for layer in sub_model.layers:\n",
    "                    layer.trainable = False\n",
    "            else:\n",
    "                for layer in sub_model.layers:\n",
    "                    layer.trainable = True\n",
    "        \n",
    "    # Create the ensemble model\n",
    "    inputs = [sub_model.input for sub_model in sub_models]\n",
    "    outputs = [sub_model.output for sub_model in sub_models]\n",
    "    concat = tf.keras.layers.Concatenate()(outputs)\n",
    "    ensemble_output = tf.keras.layers.Dense(1, activation='sigmoid')(concat)\n",
    "    ensemble_output = tf.keras.layers.Flatten()(ensemble_output)\n",
    "    ensemble_model = tf.keras.Model(inputs=inputs, outputs=ensemble_output)\n",
    "\n",
    "    # Compile the ensemble model\n",
    "    ensemble_model.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "    return ensemble_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ensemble(ensemble_model, X_test, y_test):\n",
    "    '''Evaluates the ensemble model on the test set.'''\n",
    "    # TODO NEEDS IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Experiment Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elman_only_ensemble_experiment(hidden_count_list=[10, 25, 50]):\n",
    "    '''Creates elman sub-models, makes an ensemble out of them,\n",
    "    trains the ensemble, reports test accuracy and returns the model.'''\n",
    "\n",
    "    # Create the sub-models\n",
    "    elman_submodels = create_elman_submodels(hidden_count_list)\n",
    "\n",
    "    # Create the ensemble model\n",
    "    ensemble_model = create_ensemble_model(elman_submodels)\n",
    "\n",
    "    # Copy X_train and X_validation for all of the sub-models\n",
    "    X_train_ensemble = [X_train for i in range(len(elman_submodels))]\n",
    "    X_validation_ensemble = [X_validation for i in range(len(elman_submodels))]\n",
    "    X_test_ensemble = [X_test for i in range(len(elman_submodels))]\n",
    "    \n",
    "    # Train the ensemble model\n",
    "    ensemble_model.fit(\n",
    "        X_train_ensemble,\n",
    "        y_train,\n",
    "        batch_size=1,\n",
    "        epochs=30,\n",
    "        validation_data=(X_validation_ensemble, y_validation),\n",
    "        callbacks=[tf.keras.callbacks.TensorBoard(log_dir='logs/elman_only_ensemble-{}'.format(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))])\n",
    "\n",
    "    # Report test accuracy\n",
    "    # evaluate_ensemble(ensemble_model, X_test_ensemble, y_test)\n",
    "    test_accuracy = 0.6\n",
    "\n",
    "    return ensemble_model, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jordan_only_ensemble_experiment(hidden_count_list=[10, 25, 50]):\n",
    "    '''Creates jordan sub-models, makes an ensemble out of them,\n",
    "    trains the ensemble, reports test accuracy and returns the model.'''\n",
    "\n",
    "    # Create the sub-models\n",
    "    jordan_submodels = create_jordan_submodels(hidden_count_list)\n",
    "\n",
    "    # Create the ensemble model\n",
    "    ensemble_model = create_ensemble_model(jordan_submodels)\n",
    "\n",
    "    # Copy X_train and X_validation for all of the sub-models\n",
    "    X_train_ensemble = [X_train for i in range(len(jordan_submodels))]\n",
    "    X_validation_ensemble = [X_validation for i in range(len(jordan_submodels))]\n",
    "    X_test_ensemble = [X_test for i in range(len(jordan_submodels))]\n",
    "    \n",
    "    # Train the ensemble model\n",
    "    ensemble_model.fit(\n",
    "        X_train_ensemble,\n",
    "        y_train,\n",
    "        batch_size=1,\n",
    "        epochs=30,\n",
    "        validation_data=(X_validation_ensemble, y_validation),\n",
    "        callbacks=[tf.keras.callbacks.TensorBoard(log_dir='logs/jordan_only_ensemble-{}'.format(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))])\n",
    "\n",
    "    # Report test accuracy\n",
    "    # evaluate_ensemble(ensemble_model, X_test_ensemble, y_test)\n",
    "    test_accuracy = 0.6\n",
    "\n",
    "    return ensemble_model, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def endgame_ensemble_experiment(elman_hidden_count_list=[10, 25, 50], jordan_hidden_count_list=[10, 25, 50]):\n",
    "    '''Creates elman and jordan sub-models, makes an ensemble out of them,\n",
    "    trains the ensemble, reports test accuracy and returns the model.'''\n",
    "\n",
    "    # Create the sub-models\n",
    "    elman_submodels = []\n",
    "    if len(elman_hidden_count_list)>0:\n",
    "        elman_submodels = create_elman_submodels(elman_hidden_count_list)\n",
    "\n",
    "    jordan_submodels = []\n",
    "    if len(jordan_hidden_count_list)>0:\n",
    "        jordan_submodels = create_jordan_submodels(jordan_hidden_count_list)\n",
    "\n",
    "    # Total count of sub-models\n",
    "    total_submodels = len(elman_submodels) + len(jordan_submodels)\n",
    "\n",
    "    # Split X_train for each sub-model \n",
    "    X_train_list = []\n",
    "    for i in range(total_submodels):\n",
    "        X_train_current = X_train[int(i*X_train.shape[0]/total_submodels):int((i+1)*X_train.shape[0]/total_submodels)]\n",
    "        X_train_list.append(X_train_current)\n",
    "\n",
    "    # Choose X_train and copy X_validation for all of the sub-models\n",
    "    X_train_ensemble = [X_train_list[i] for i in range(total_submodels)]\n",
    "    X_validation_ensemble = [X_validation for i in range(total_submodels)]\n",
    "    X_test_ensemble = [X_test for i in range(total_submodels)]\n",
    "    \n",
    "    for i in range(total_submodels):\n",
    "        # Create the mixed ensemble model and freeze every submodel except the i-th one\n",
    "        ensemble_model = create_ensemble_model(elman_submodels + jordan_submodels, active_index=i)\n",
    "\n",
    "        # Train the ensemble model\n",
    "        ensemble_model.fit(\n",
    "            X_train_ensemble,\n",
    "            y_train,\n",
    "            batch_size=1,\n",
    "            epochs=30,\n",
    "            validation_data=(X_validation_ensemble, y_validation),\n",
    "            callbacks=[tf.keras.callbacks.TensorBoard(log_dir='logs/endgame_ensemble-{}'.format(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))])\n",
    "\n",
    "    # Report test accuracy\n",
    "    # evaluate_ensemble(ensemble_model, X_test, y_test)\n",
    "    test_accuracy = 0.6\n",
    "\n",
    "    return ensemble_model, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (463, 15, 6)\n",
      "X.dtype: float32\n",
      "y.shape: (463,)\n",
      "y.dtype: float32\n"
     ]
    }
   ],
   "source": [
    "X, y = load_data()\n",
    "print(\"X.shape:\", X.shape)\n",
    "print(\"X.dtype:\", X.dtype)\n",
    "print(\"y.shape:\", y.shape)\n",
    "print(\"y.dtype:\", y.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Test, validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.125, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "323/323 [==============================] - 3s 4ms/step - loss: 0.9185 - acc: 0.7276 - val_loss: 0.4288 - val_acc: 0.7447\n",
      "Epoch 2/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.4120 - acc: 0.7276 - val_loss: 0.3839 - val_acc: 0.7447\n",
      "Epoch 3/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3823 - acc: 0.7585 - val_loss: 0.3640 - val_acc: 0.7447\n",
      "Epoch 4/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3584 - acc: 0.7941 - val_loss: 0.3708 - val_acc: 0.7553\n",
      "Epoch 5/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3503 - acc: 0.8173 - val_loss: 0.3412 - val_acc: 0.8191\n",
      "Epoch 6/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3392 - acc: 0.8437 - val_loss: 0.3491 - val_acc: 0.8191\n",
      "Epoch 7/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3271 - acc: 0.8498 - val_loss: 0.3211 - val_acc: 0.8404\n",
      "Epoch 8/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3206 - acc: 0.8282 - val_loss: 0.3144 - val_acc: 0.8404\n",
      "Epoch 9/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3037 - acc: 0.8483 - val_loss: 0.3195 - val_acc: 0.8191\n",
      "Epoch 10/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3218 - acc: 0.8545 - val_loss: 0.3249 - val_acc: 0.8298\n",
      "Epoch 11/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2977 - acc: 0.8591 - val_loss: 0.3242 - val_acc: 0.8298\n",
      "Epoch 12/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2916 - acc: 0.8359 - val_loss: 0.3104 - val_acc: 0.8298\n",
      "Epoch 13/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2874 - acc: 0.8545 - val_loss: 0.3185 - val_acc: 0.8298\n",
      "Epoch 14/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2751 - acc: 0.8762 - val_loss: 0.3022 - val_acc: 0.8298\n",
      "Epoch 15/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2986 - acc: 0.8746 - val_loss: 0.2974 - val_acc: 0.8404\n",
      "Epoch 16/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2686 - acc: 0.8746 - val_loss: 0.2780 - val_acc: 0.8723\n",
      "Epoch 17/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2652 - acc: 0.8808 - val_loss: 0.2833 - val_acc: 0.8298\n",
      "Epoch 18/30\n",
      "323/323 [==============================] - 2s 5ms/step - loss: 0.2637 - acc: 0.8669 - val_loss: 0.2894 - val_acc: 0.8617\n",
      "Epoch 19/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3038 - acc: 0.8607 - val_loss: 0.3081 - val_acc: 0.8298\n",
      "Epoch 20/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2612 - acc: 0.8808 - val_loss: 0.2741 - val_acc: 0.8830\n",
      "Epoch 21/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2526 - acc: 0.8839 - val_loss: 0.2704 - val_acc: 0.8404\n",
      "Epoch 22/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2916 - acc: 0.8669 - val_loss: 0.2788 - val_acc: 0.8511\n",
      "Epoch 23/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2502 - acc: 0.8885 - val_loss: 0.2795 - val_acc: 0.8511\n",
      "Epoch 24/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2563 - acc: 0.8808 - val_loss: 0.2737 - val_acc: 0.8723\n",
      "Epoch 25/30\n",
      "323/323 [==============================] - 2s 5ms/step - loss: 0.2355 - acc: 0.8932 - val_loss: 0.2670 - val_acc: 0.8511\n",
      "Epoch 26/30\n",
      "323/323 [==============================] - 1s 4ms/step - loss: 0.2264 - acc: 0.9056 - val_loss: 0.2552 - val_acc: 0.8511\n",
      "Epoch 27/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2338 - acc: 0.8839 - val_loss: 0.2595 - val_acc: 0.8723\n",
      "Epoch 28/30\n",
      "323/323 [==============================] - 1s 4ms/step - loss: 0.2126 - acc: 0.8978 - val_loss: 0.2389 - val_acc: 0.8723\n",
      "Epoch 29/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2235 - acc: 0.8947 - val_loss: 0.2711 - val_acc: 0.8511\n",
      "Epoch 30/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2158 - acc: 0.9040 - val_loss: 0.2406 - val_acc: 0.8511\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x224b2d765f0>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elman_nn = ElmanModel(input_dim=15, hidden_units=10, feature_size=6, n_classes=2)\n",
    "\n",
    "elman_nn.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['acc'])\n",
    "elman_nn.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=1,\n",
    "    epochs=30,\n",
    "    validation_data=(X_validation, y_validation),\n",
    "    callbacks=[tf.keras.callbacks.TensorBoard(log_dir='logs/elman-{}'.format(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elman_nn.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "323/323 [==============================] - 3s 5ms/step - loss: 2.3142 - acc: 0.7337 - val_loss: 2.1663 - val_acc: 0.7447\n",
      "Epoch 2/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 2.2920 - acc: 0.7415 - val_loss: 2.1437 - val_acc: 0.7766\n",
      "Epoch 3/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2804 - acc: 0.7570 - val_loss: 2.1388 - val_acc: 0.7660\n",
      "Epoch 4/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2689 - acc: 0.7802 - val_loss: 2.1346 - val_acc: 0.7766\n",
      "Epoch 5/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2614 - acc: 0.7817 - val_loss: 2.1263 - val_acc: 0.7979\n",
      "Epoch 6/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2525 - acc: 0.7802 - val_loss: 2.1286 - val_acc: 0.7553\n",
      "Epoch 7/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2523 - acc: 0.7972 - val_loss: 2.1163 - val_acc: 0.7766\n",
      "Epoch 8/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2441 - acc: 0.7895 - val_loss: 2.1067 - val_acc: 0.7872\n",
      "Epoch 9/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2655 - acc: 0.7988 - val_loss: 2.1074 - val_acc: 0.8191\n",
      "Epoch 10/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2397 - acc: 0.7926 - val_loss: 2.0993 - val_acc: 0.8085\n",
      "Epoch 11/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2357 - acc: 0.7926 - val_loss: 2.1144 - val_acc: 0.7553\n",
      "Epoch 12/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2320 - acc: 0.7926 - val_loss: 2.0908 - val_acc: 0.8085\n",
      "Epoch 13/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2243 - acc: 0.8019 - val_loss: 2.0999 - val_acc: 0.8085\n",
      "Epoch 14/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2687 - acc: 0.8034 - val_loss: 2.1016 - val_acc: 0.7979\n",
      "Epoch 15/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2241 - acc: 0.8003 - val_loss: 2.0876 - val_acc: 0.7979\n",
      "Epoch 16/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2223 - acc: 0.8050 - val_loss: 2.1226 - val_acc: 0.7553\n",
      "Epoch 17/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2168 - acc: 0.8034 - val_loss: 2.0928 - val_acc: 0.8085\n",
      "Epoch 18/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2197 - acc: 0.7972 - val_loss: 2.0811 - val_acc: 0.8191\n",
      "Epoch 19/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2101 - acc: 0.8034 - val_loss: 2.0952 - val_acc: 0.8085\n",
      "Epoch 20/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2078 - acc: 0.8019 - val_loss: 2.0889 - val_acc: 0.7979\n",
      "Epoch 21/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2046 - acc: 0.8096 - val_loss: 2.0814 - val_acc: 0.7979\n",
      "Epoch 22/30\n",
      "323/323 [==============================] - 1s 4ms/step - loss: 2.2416 - acc: 0.8096 - val_loss: 2.1411 - val_acc: 0.7660\n",
      "Epoch 23/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2271 - acc: 0.7864 - val_loss: 2.1071 - val_acc: 0.7872\n",
      "Epoch 24/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.3144 - acc: 0.8050 - val_loss: 2.2809 - val_acc: 0.7872\n",
      "Epoch 25/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.4298 - acc: 0.7926 - val_loss: 2.0835 - val_acc: 0.7766\n",
      "Epoch 26/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2052 - acc: 0.7988 - val_loss: 2.0865 - val_acc: 0.7872\n",
      "Epoch 27/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2066 - acc: 0.8080 - val_loss: 2.0885 - val_acc: 0.7979\n",
      "Epoch 28/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 2.1980 - acc: 0.8142 - val_loss: 2.0821 - val_acc: 0.7872\n",
      "Epoch 29/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.1942 - acc: 0.8142 - val_loss: 2.0820 - val_acc: 0.8191\n",
      "Epoch 30/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.1923 - acc: 0.8127 - val_loss: 2.0830 - val_acc: 0.7979\n",
      "Epoch 1/30\n",
      "323/323 [==============================] - 3s 4ms/step - loss: 0.4529 - acc: 0.7461 - val_loss: 0.3661 - val_acc: 0.7660\n",
      "Epoch 2/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.4374 - acc: 0.7678 - val_loss: 0.3536 - val_acc: 0.7766\n",
      "Epoch 3/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3411 - acc: 0.7972 - val_loss: 0.3318 - val_acc: 0.8404\n",
      "Epoch 4/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3186 - acc: 0.8297 - val_loss: 0.3621 - val_acc: 0.7553\n",
      "Epoch 5/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3110 - acc: 0.8452 - val_loss: 0.3052 - val_acc: 0.7872\n",
      "Epoch 6/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3011 - acc: 0.8406 - val_loss: 0.3422 - val_acc: 0.7872\n",
      "Epoch 7/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2997 - acc: 0.8251 - val_loss: 0.2883 - val_acc: 0.8404\n",
      "Epoch 8/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2747 - acc: 0.8406 - val_loss: 0.2908 - val_acc: 0.8298\n",
      "Epoch 9/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2854 - acc: 0.8514 - val_loss: 0.2882 - val_acc: 0.8723\n",
      "Epoch 10/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2588 - acc: 0.8638 - val_loss: 0.2542 - val_acc: 0.8723\n",
      "Epoch 11/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2278 - acc: 0.8824 - val_loss: 0.2644 - val_acc: 0.8511\n",
      "Epoch 12/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2088 - acc: 0.8839 - val_loss: 0.2418 - val_acc: 0.8723\n",
      "Epoch 13/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2017 - acc: 0.8963 - val_loss: 0.2465 - val_acc: 0.8617\n",
      "Epoch 14/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2572 - acc: 0.8916 - val_loss: 0.2202 - val_acc: 0.8723\n",
      "Epoch 15/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2340 - acc: 0.8793 - val_loss: 0.2138 - val_acc: 0.8936\n",
      "Epoch 16/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2009 - acc: 0.9102 - val_loss: 0.2604 - val_acc: 0.8404\n",
      "Epoch 17/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2546 - acc: 0.8560 - val_loss: 0.2109 - val_acc: 0.8936\n",
      "Epoch 18/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.1787 - acc: 0.9118 - val_loss: 0.2389 - val_acc: 0.8723\n",
      "Epoch 19/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.1678 - acc: 0.9133 - val_loss: 0.1891 - val_acc: 0.9149\n",
      "Epoch 20/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.1614 - acc: 0.9319 - val_loss: 0.1861 - val_acc: 0.8723\n",
      "Epoch 21/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.1519 - acc: 0.9257 - val_loss: 0.1654 - val_acc: 0.9362\n",
      "Epoch 22/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.1419 - acc: 0.9350 - val_loss: 0.4825 - val_acc: 0.8936\n",
      "Epoch 23/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.6733 - acc: 0.9025 - val_loss: 0.1615 - val_acc: 0.9362\n",
      "Epoch 24/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.1835 - acc: 0.9149 - val_loss: 0.1967 - val_acc: 0.9149\n",
      "Epoch 25/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.1601 - acc: 0.9195 - val_loss: 0.1733 - val_acc: 0.8936\n",
      "Epoch 26/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.1403 - acc: 0.9257 - val_loss: 0.1697 - val_acc: 0.9362\n",
      "Epoch 27/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.1288 - acc: 0.9350 - val_loss: 0.1526 - val_acc: 0.9362\n",
      "Epoch 28/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.1391 - acc: 0.9334 - val_loss: 0.1392 - val_acc: 0.9043\n",
      "Epoch 29/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.1297 - acc: 0.9350 - val_loss: 0.1332 - val_acc: 0.9574\n",
      "Epoch 30/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.1161 - acc: 0.9458 - val_loss: 0.1929 - val_acc: 0.8936\n",
      "Epoch 1/30\n",
      "323/323 [==============================] - 3s 4ms/step - loss: 0.4080 - acc: 0.7415 - val_loss: 0.3434 - val_acc: 0.7872\n",
      "Epoch 2/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3308 - acc: 0.8282 - val_loss: 0.3259 - val_acc: 0.7660\n",
      "Epoch 3/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3315 - acc: 0.8142 - val_loss: 0.3210 - val_acc: 0.7872\n",
      "Epoch 4/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3332 - acc: 0.8142 - val_loss: 0.2856 - val_acc: 0.8404\n",
      "Epoch 5/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3539 - acc: 0.8204 - val_loss: 0.3178 - val_acc: 0.8085\n",
      "Epoch 6/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3121 - acc: 0.8297 - val_loss: 0.3300 - val_acc: 0.8085\n",
      "Epoch 7/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3167 - acc: 0.8297 - val_loss: 0.3161 - val_acc: 0.8085\n",
      "Epoch 8/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2881 - acc: 0.8452 - val_loss: 0.3090 - val_acc: 0.7872\n",
      "Epoch 9/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3989 - acc: 0.8204 - val_loss: 0.4920 - val_acc: 0.8085\n",
      "Epoch 10/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3558 - acc: 0.8328 - val_loss: 0.3417 - val_acc: 0.7872\n",
      "Epoch 11/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2878 - acc: 0.8607 - val_loss: 0.3048 - val_acc: 0.8511\n",
      "Epoch 12/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2835 - acc: 0.8483 - val_loss: 0.3342 - val_acc: 0.8085\n",
      "Epoch 13/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2719 - acc: 0.8700 - val_loss: 0.2888 - val_acc: 0.8617\n",
      "Epoch 14/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2690 - acc: 0.8560 - val_loss: 0.2771 - val_acc: 0.8404\n",
      "Epoch 15/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2732 - acc: 0.8467 - val_loss: 0.2872 - val_acc: 0.8298\n",
      "Epoch 16/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2706 - acc: 0.8731 - val_loss: 0.3496 - val_acc: 0.7660\n",
      "Epoch 17/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2459 - acc: 0.8576 - val_loss: 0.2668 - val_acc: 0.8404\n",
      "Epoch 18/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2112 - acc: 0.8901 - val_loss: 0.2574 - val_acc: 0.8830\n",
      "Epoch 19/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2582 - acc: 0.8947 - val_loss: 0.2931 - val_acc: 0.7872\n",
      "Epoch 20/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2357 - acc: 0.8839 - val_loss: 0.2591 - val_acc: 0.8298\n",
      "Epoch 21/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2272 - acc: 0.9087 - val_loss: 0.2212 - val_acc: 0.8830\n",
      "Epoch 22/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2194 - acc: 0.8762 - val_loss: 0.3377 - val_acc: 0.7660\n",
      "Epoch 23/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.4331 - acc: 0.7988 - val_loss: 0.3587 - val_acc: 0.8085\n",
      "Epoch 24/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2771 - acc: 0.8653 - val_loss: 0.2607 - val_acc: 0.8936\n",
      "Epoch 25/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2233 - acc: 0.9040 - val_loss: 0.2371 - val_acc: 0.9255\n",
      "Epoch 26/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2171 - acc: 0.8994 - val_loss: 0.2191 - val_acc: 0.9255\n",
      "Epoch 27/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2074 - acc: 0.9056 - val_loss: 0.2072 - val_acc: 0.9362\n",
      "Epoch 28/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2027 - acc: 0.9087 - val_loss: 0.2008 - val_acc: 0.9255\n",
      "Epoch 29/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.1879 - acc: 0.9102 - val_loss: 0.1941 - val_acc: 0.9681\n",
      "Epoch 30/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.1851 - acc: 0.9102 - val_loss: 0.1735 - val_acc: 0.9468\n"
     ]
    }
   ],
   "source": [
    "# Experiment with different hidden layer counts\n",
    "elman_10, elman_10_score = train_elman(10)\n",
    "elman_25, elman_25_score = train_elman(25)\n",
    "elman_50, elman_50_score = train_elman(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elman_10_score: 0.7\n",
      "elman_25_score: 0.7\n",
      "elman_50_score: 0.7\n"
     ]
    }
   ],
   "source": [
    "print(\"elman_10_score:\", elman_10_score)\n",
    "print(\"elman_25_score:\", elman_25_score)\n",
    "print(\"elman_50_score:\", elman_50_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jordan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "323/323 [==============================] - 3s 4ms/step - loss: 2.3574 - acc: 0.7276 - val_loss: 2.1731 - val_acc: 0.7447\n",
      "Epoch 2/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 1.0798 - acc: 0.7198 - val_loss: 0.3887 - val_acc: 0.7234\n",
      "Epoch 3/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3848 - acc: 0.7353 - val_loss: 0.3648 - val_acc: 0.7766\n",
      "Epoch 4/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3583 - acc: 0.7724 - val_loss: 0.3387 - val_acc: 0.7979\n",
      "Epoch 5/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3408 - acc: 0.8158 - val_loss: 0.3472 - val_acc: 0.8085\n",
      "Epoch 6/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3358 - acc: 0.8158 - val_loss: 0.3267 - val_acc: 0.8191\n",
      "Epoch 7/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3255 - acc: 0.8251 - val_loss: 0.3182 - val_acc: 0.8191\n",
      "Epoch 8/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3500 - acc: 0.8173 - val_loss: 0.3681 - val_acc: 0.7340\n",
      "Epoch 9/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3328 - acc: 0.8235 - val_loss: 0.3397 - val_acc: 0.8191\n",
      "Epoch 10/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3127 - acc: 0.8375 - val_loss: 0.3241 - val_acc: 0.8085\n",
      "Epoch 11/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3033 - acc: 0.8406 - val_loss: 0.3195 - val_acc: 0.8085\n",
      "Epoch 12/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2950 - acc: 0.8514 - val_loss: 0.5962 - val_acc: 0.8404\n",
      "Epoch 13/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3053 - acc: 0.8406 - val_loss: 0.3107 - val_acc: 0.8191\n",
      "Epoch 14/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2891 - acc: 0.8375 - val_loss: 0.3077 - val_acc: 0.8404\n",
      "Epoch 15/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3013 - acc: 0.8406 - val_loss: 0.3143 - val_acc: 0.8617\n",
      "Epoch 16/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2963 - acc: 0.8762 - val_loss: 0.3943 - val_acc: 0.7660\n",
      "Epoch 17/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3410 - acc: 0.8034 - val_loss: 0.3521 - val_acc: 0.7660\n",
      "Epoch 18/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3236 - acc: 0.8080 - val_loss: 0.3385 - val_acc: 0.7872\n",
      "Epoch 19/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3121 - acc: 0.8328 - val_loss: 0.3452 - val_acc: 0.7660\n",
      "Epoch 20/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3083 - acc: 0.8251 - val_loss: 0.3349 - val_acc: 0.7979\n",
      "Epoch 21/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.3023 - acc: 0.8328 - val_loss: 0.3276 - val_acc: 0.8085\n",
      "Epoch 22/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2971 - acc: 0.8421 - val_loss: 0.3257 - val_acc: 0.8085\n",
      "Epoch 23/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2929 - acc: 0.8406 - val_loss: 0.3124 - val_acc: 0.8085\n",
      "Epoch 24/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2901 - acc: 0.8406 - val_loss: 0.3168 - val_acc: 0.8085\n",
      "Epoch 25/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2855 - acc: 0.8421 - val_loss: 0.3135 - val_acc: 0.7979\n",
      "Epoch 26/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2815 - acc: 0.8545 - val_loss: 0.2966 - val_acc: 0.8404\n",
      "Epoch 27/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2778 - acc: 0.8591 - val_loss: 0.2881 - val_acc: 0.8404\n",
      "Epoch 28/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2732 - acc: 0.8576 - val_loss: 0.2871 - val_acc: 0.8404\n",
      "Epoch 29/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2731 - acc: 0.8514 - val_loss: 0.2780 - val_acc: 0.8298\n",
      "Epoch 30/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2711 - acc: 0.8529 - val_loss: 0.2773 - val_acc: 0.8617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x224ba712860>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jordan_nn = JordanModel(input_dim=15, hidden_units=10, feature_size=6, n_classes=2)\n",
    "\n",
    "jordan_nn.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['acc'])\n",
    "\n",
    "jordan_nn.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=1,\n",
    "    epochs=30,\n",
    "    validation_data=(X_validation, y_validation),\n",
    "    callbacks=[tf.keras.callbacks.TensorBoard(log_dir='logs/jordan-{}'.format(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jordan_nn.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "323/323 [==============================] - 3s 4ms/step - loss: 2.5873 - acc: 0.7276 - val_loss: 2.2141 - val_acc: 0.7447\n",
      "Epoch 2/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.3226 - acc: 0.7276 - val_loss: 2.1741 - val_acc: 0.7447\n",
      "Epoch 3/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.3022 - acc: 0.7276 - val_loss: 2.1598 - val_acc: 0.7447\n",
      "Epoch 4/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2894 - acc: 0.7353 - val_loss: 2.1504 - val_acc: 0.7660\n",
      "Epoch 5/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2819 - acc: 0.7616 - val_loss: 2.1473 - val_acc: 0.7660\n",
      "Epoch 6/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2752 - acc: 0.7678 - val_loss: 2.1396 - val_acc: 0.7766\n",
      "Epoch 7/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2707 - acc: 0.7740 - val_loss: 2.1333 - val_acc: 0.7872\n",
      "Epoch 8/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2642 - acc: 0.7833 - val_loss: 2.1320 - val_acc: 0.7766\n",
      "Epoch 9/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2636 - acc: 0.7693 - val_loss: 2.1330 - val_acc: 0.7766\n",
      "Epoch 10/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2590 - acc: 0.7771 - val_loss: 2.1313 - val_acc: 0.7766\n",
      "Epoch 11/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2561 - acc: 0.7864 - val_loss: 2.1311 - val_acc: 0.7872\n",
      "Epoch 12/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 2.2512 - acc: 0.7833 - val_loss: 2.1306 - val_acc: 0.7766\n",
      "Epoch 13/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2487 - acc: 0.7864 - val_loss: 2.1352 - val_acc: 0.7872\n",
      "Epoch 14/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2463 - acc: 0.7879 - val_loss: 2.1138 - val_acc: 0.7766\n",
      "Epoch 15/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2511 - acc: 0.7802 - val_loss: 2.1170 - val_acc: 0.7872\n",
      "Epoch 16/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2439 - acc: 0.7817 - val_loss: 2.1199 - val_acc: 0.7872\n",
      "Epoch 17/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2557 - acc: 0.7941 - val_loss: 2.1077 - val_acc: 0.7872\n",
      "Epoch 18/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2838 - acc: 0.7833 - val_loss: 2.1066 - val_acc: 0.7979\n",
      "Epoch 19/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2538 - acc: 0.7941 - val_loss: 2.1076 - val_acc: 0.8191\n",
      "Epoch 20/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2692 - acc: 0.8003 - val_loss: 2.1363 - val_acc: 0.7872\n",
      "Epoch 21/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2344 - acc: 0.7972 - val_loss: 2.1123 - val_acc: 0.7979\n",
      "Epoch 22/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2270 - acc: 0.7988 - val_loss: 2.1088 - val_acc: 0.8085\n",
      "Epoch 23/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2235 - acc: 0.8096 - val_loss: 2.1049 - val_acc: 0.7979\n",
      "Epoch 24/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2146 - acc: 0.8034 - val_loss: 2.1164 - val_acc: 0.7766\n",
      "Epoch 25/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2099 - acc: 0.8111 - val_loss: 2.0845 - val_acc: 0.8191\n",
      "Epoch 26/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2857 - acc: 0.7817 - val_loss: 2.1066 - val_acc: 0.7979\n",
      "Epoch 27/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2212 - acc: 0.8065 - val_loss: 2.0911 - val_acc: 0.8085\n",
      "Epoch 28/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2126 - acc: 0.8096 - val_loss: 2.0981 - val_acc: 0.8085\n",
      "Epoch 29/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2726 - acc: 0.7740 - val_loss: 2.1243 - val_acc: 0.7872\n",
      "Epoch 30/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.2395 - acc: 0.7817 - val_loss: 2.0983 - val_acc: 0.7979\n",
      "Epoch 1/30\n",
      "323/323 [==============================] - 3s 4ms/step - loss: 2.0697 - acc: 0.7291 - val_loss: 0.3877 - val_acc: 0.7447\n",
      "Epoch 2/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3934 - acc: 0.7817 - val_loss: 0.3572 - val_acc: 0.7979\n",
      "Epoch 3/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3601 - acc: 0.8173 - val_loss: 0.3875 - val_acc: 0.7553\n",
      "Epoch 4/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3379 - acc: 0.8173 - val_loss: 0.3325 - val_acc: 0.7872\n",
      "Epoch 5/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3023 - acc: 0.8390 - val_loss: 0.3089 - val_acc: 0.8191\n",
      "Epoch 6/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2965 - acc: 0.8452 - val_loss: 0.3119 - val_acc: 0.8191\n",
      "Epoch 7/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2930 - acc: 0.8359 - val_loss: 0.3057 - val_acc: 0.8298\n",
      "Epoch 8/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3236 - acc: 0.8545 - val_loss: 0.3650 - val_acc: 0.7872\n",
      "Epoch 9/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.4549 - acc: 0.8189 - val_loss: 0.3208 - val_acc: 0.8298\n",
      "Epoch 10/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2913 - acc: 0.8514 - val_loss: 0.3044 - val_acc: 0.8617\n",
      "Epoch 11/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2705 - acc: 0.8607 - val_loss: 0.2742 - val_acc: 0.8511\n",
      "Epoch 12/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.4670 - acc: 0.8204 - val_loss: 0.3415 - val_acc: 0.7872\n",
      "Epoch 13/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.3140 - acc: 0.8034 - val_loss: 0.3166 - val_acc: 0.7979\n",
      "Epoch 14/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2794 - acc: 0.8669 - val_loss: 0.3514 - val_acc: 0.7872\n",
      "Epoch 15/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2949 - acc: 0.8483 - val_loss: 0.3236 - val_acc: 0.7872\n",
      "Epoch 16/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2587 - acc: 0.8638 - val_loss: 0.3070 - val_acc: 0.7979\n",
      "Epoch 17/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2707 - acc: 0.8421 - val_loss: 0.2669 - val_acc: 0.8511\n",
      "Epoch 18/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2411 - acc: 0.8731 - val_loss: 0.2652 - val_acc: 0.8723\n",
      "Epoch 19/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3165 - acc: 0.8916 - val_loss: 0.3191 - val_acc: 0.8085\n",
      "Epoch 20/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2125 - acc: 0.8669 - val_loss: 0.6038 - val_acc: 0.8404\n",
      "Epoch 21/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2391 - acc: 0.8916 - val_loss: 0.5659 - val_acc: 0.7128\n",
      "Epoch 22/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2894 - acc: 0.8313 - val_loss: 0.2791 - val_acc: 0.8617\n",
      "Epoch 23/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2216 - acc: 0.8839 - val_loss: 0.2310 - val_acc: 0.8511\n",
      "Epoch 24/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2345 - acc: 0.8947 - val_loss: 0.2465 - val_acc: 0.8723\n",
      "Epoch 25/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2213 - acc: 0.9102 - val_loss: 0.2315 - val_acc: 0.9255\n",
      "Epoch 26/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3690 - acc: 0.9040 - val_loss: 0.3164 - val_acc: 0.7766\n",
      "Epoch 27/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2181 - acc: 0.8870 - val_loss: 0.2336 - val_acc: 0.8830\n",
      "Epoch 28/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.1855 - acc: 0.9056 - val_loss: 0.2237 - val_acc: 0.9255\n",
      "Epoch 29/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.1744 - acc: 0.9211 - val_loss: 0.2720 - val_acc: 0.8617\n",
      "Epoch 30/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.1610 - acc: 0.9319 - val_loss: 0.1903 - val_acc: 0.8830\n",
      "Epoch 1/30\n",
      "323/323 [==============================] - 4s 4ms/step - loss: 0.5374 - acc: 0.7260 - val_loss: 0.4456 - val_acc: 0.7340\n",
      "Epoch 2/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3742 - acc: 0.7817 - val_loss: 0.3514 - val_acc: 0.8191\n",
      "Epoch 3/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.3436 - acc: 0.7957 - val_loss: 0.8811 - val_acc: 0.8191\n",
      "Epoch 4/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.3734 - acc: 0.8189 - val_loss: 0.3452 - val_acc: 0.8085\n",
      "Epoch 5/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3615 - acc: 0.8142 - val_loss: 0.5686 - val_acc: 0.7021\n",
      "Epoch 6/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.4640 - acc: 0.7214 - val_loss: 0.3555 - val_acc: 0.7660\n",
      "Epoch 7/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.3522 - acc: 0.7755 - val_loss: 0.3340 - val_acc: 0.8404\n",
      "Epoch 8/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.3289 - acc: 0.8111 - val_loss: 0.3270 - val_acc: 0.7766\n",
      "Epoch 9/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.3190 - acc: 0.8297 - val_loss: 0.3454 - val_acc: 0.7660\n",
      "Epoch 10/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3167 - acc: 0.8282 - val_loss: 0.3127 - val_acc: 0.8191\n",
      "Epoch 11/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3065 - acc: 0.8158 - val_loss: 0.3106 - val_acc: 0.8298\n",
      "Epoch 12/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3030 - acc: 0.8080 - val_loss: 0.3114 - val_acc: 0.7872\n",
      "Epoch 13/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2966 - acc: 0.8359 - val_loss: 0.3025 - val_acc: 0.8298\n",
      "Epoch 14/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2885 - acc: 0.8375 - val_loss: 0.2918 - val_acc: 0.8191\n",
      "Epoch 15/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2888 - acc: 0.8313 - val_loss: 0.2971 - val_acc: 0.7979\n",
      "Epoch 16/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2754 - acc: 0.8545 - val_loss: 0.3083 - val_acc: 0.7979\n",
      "Epoch 17/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3058 - acc: 0.8467 - val_loss: 0.3086 - val_acc: 0.8298\n",
      "Epoch 18/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2771 - acc: 0.8359 - val_loss: 0.3320 - val_acc: 0.7979\n",
      "Epoch 19/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2634 - acc: 0.8545 - val_loss: 0.2799 - val_acc: 0.8511\n",
      "Epoch 20/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2505 - acc: 0.8700 - val_loss: 0.2905 - val_acc: 0.8511\n",
      "Epoch 21/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2405 - acc: 0.8762 - val_loss: 0.2933 - val_acc: 0.8085\n",
      "Epoch 22/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.4972 - acc: 0.8050 - val_loss: 0.7699 - val_acc: 0.7553\n",
      "Epoch 23/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.4884 - acc: 0.7724 - val_loss: 0.3494 - val_acc: 0.8085\n",
      "Epoch 24/30\n",
      "323/323 [==============================] - 1s 4ms/step - loss: 0.3302 - acc: 0.8019 - val_loss: 0.3119 - val_acc: 0.7979\n",
      "Epoch 25/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2824 - acc: 0.8406 - val_loss: 0.5907 - val_acc: 0.8191\n",
      "Epoch 26/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2773 - acc: 0.8344 - val_loss: 0.2694 - val_acc: 0.8723\n",
      "Epoch 27/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2824 - acc: 0.8529 - val_loss: 0.2659 - val_acc: 0.8617\n",
      "Epoch 28/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2921 - acc: 0.8700 - val_loss: 0.2918 - val_acc: 0.8404\n",
      "Epoch 29/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2477 - acc: 0.8700 - val_loss: 0.2675 - val_acc: 0.8191\n",
      "Epoch 30/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2538 - acc: 0.8777 - val_loss: 0.2179 - val_acc: 0.9149\n"
     ]
    }
   ],
   "source": [
    "jordan_10, jordan_10_score = train_jordan(10)\n",
    "jordan_25, jordan_25_score = train_jordan(25)\n",
    "jordan_50, jordan_50_score = train_jordan(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jordan_10_score: 0.4\n",
      "jordan_25_score: 0.4\n",
      "jordan_50_score: 0.4\n"
     ]
    }
   ],
   "source": [
    "print(\"jordan_10_score:\", jordan_10_score)\n",
    "print(\"jordan_25_score:\", jordan_25_score)\n",
    "print(\"jordan_50_score:\", jordan_50_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elman Only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... \n",
      "Epoch 1/30\n",
      "323/323 [==============================] - 5s 6ms/step - loss: 0.6208 - acc: 0.6734 - val_loss: 0.5153 - val_acc: 0.7553\n",
      "Epoch 2/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.4748 - acc: 0.7972 - val_loss: 0.4240 - val_acc: 0.7979\n",
      "Epoch 3/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.4111 - acc: 0.8158 - val_loss: 0.3779 - val_acc: 0.8298\n",
      "Epoch 4/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3707 - acc: 0.8220 - val_loss: 0.4045 - val_acc: 0.7447\n",
      "Epoch 5/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.3533 - acc: 0.8189 - val_loss: 0.3564 - val_acc: 0.8723\n",
      "Epoch 6/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3217 - acc: 0.8653 - val_loss: 0.3300 - val_acc: 0.8723\n",
      "Epoch 7/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.3533 - acc: 0.8390 - val_loss: 0.3641 - val_acc: 0.8617\n",
      "Epoch 8/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.3047 - acc: 0.8808 - val_loss: 0.3802 - val_acc: 0.7979\n",
      "Epoch 9/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2865 - acc: 0.8576 - val_loss: 0.3340 - val_acc: 0.8723\n",
      "Epoch 10/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2682 - acc: 0.8854 - val_loss: 0.3226 - val_acc: 0.7979\n",
      "Epoch 11/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2673 - acc: 0.8746 - val_loss: 0.3583 - val_acc: 0.8298\n",
      "Epoch 12/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2616 - acc: 0.8793 - val_loss: 0.3045 - val_acc: 0.8191\n",
      "Epoch 13/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2651 - acc: 0.8498 - val_loss: 0.2983 - val_acc: 0.8830\n",
      "Epoch 14/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2387 - acc: 0.8793 - val_loss: 0.2854 - val_acc: 0.8191\n",
      "Epoch 15/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2274 - acc: 0.8932 - val_loss: 0.2863 - val_acc: 0.8404\n",
      "Epoch 16/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2239 - acc: 0.8808 - val_loss: 0.2590 - val_acc: 0.8936\n",
      "Epoch 17/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.1999 - acc: 0.9087 - val_loss: 0.2779 - val_acc: 0.8404\n",
      "Epoch 18/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2137 - acc: 0.9071 - val_loss: 0.2523 - val_acc: 0.8936\n",
      "Epoch 19/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.1909 - acc: 0.9087 - val_loss: 0.2493 - val_acc: 0.8936\n",
      "Epoch 20/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.1804 - acc: 0.9149 - val_loss: 0.2737 - val_acc: 0.8936\n",
      "Epoch 21/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.1946 - acc: 0.9071 - val_loss: 0.2270 - val_acc: 0.8936\n",
      "Epoch 22/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2198 - acc: 0.8885 - val_loss: 0.2053 - val_acc: 0.8936\n",
      "Epoch 23/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.1718 - acc: 0.9257 - val_loss: 0.2065 - val_acc: 0.8830\n",
      "Epoch 24/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.1564 - acc: 0.9412 - val_loss: 0.2115 - val_acc: 0.8936\n",
      "Epoch 25/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.1565 - acc: 0.9412 - val_loss: 0.1786 - val_acc: 0.9043\n",
      "Epoch 26/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.1406 - acc: 0.9505 - val_loss: 0.1939 - val_acc: 0.9362\n",
      "Epoch 27/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.1443 - acc: 0.9412 - val_loss: 0.2552 - val_acc: 0.8936\n",
      "Epoch 28/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.1528 - acc: 0.9505 - val_loss: 0.2649 - val_acc: 0.8830\n",
      "Epoch 29/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.1547 - acc: 0.9381 - val_loss: 0.2112 - val_acc: 0.9255\n",
      "Epoch 30/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.1514 - acc: 0.9427 - val_loss: 0.2196 - val_acc: 0.8936\n"
     ]
    }
   ],
   "source": [
    "elman_only_ensemble, elman_only_ensemble_score = elman_only_ensemble_experiment(\n",
    "    hidden_count_list=[10, 25, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer \"model_9\" expects 3 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor: shape=(93, 15, 6), dtype=float32, numpy=\narray([[[  46.,   29.,   59.,  -98.,  125.,  -16.],\n        [  19.,   18.,   96.,  -42.,   10.,   -6.],\n        [  27.,   23.,   93.,  -42.,   31.,   -9.],\n        ...,\n        [  -4.,   -7.,   84.,   -2.,  -16.,   -8.],\n        [  -3.,   -3.,   80.,   -7.,  -13.,   -1.],\n        [   0.,  -15.,   86.,   13.,  -11.,   -1.]],\n\n       [[  -4.,    3.,   76.,  -11.,  -16.,   -5.],\n        [  -2.,  -13.,   91.,   18.,  -12.,   -5.],\n        [   0.,    0.,   71.,   -9.,   -6.,   -4.],\n        ...,\n        [  -4.,   -1.,   83.,   -7.,  -18.,  -13.],\n        [   2.,   -9.,   83.,    7.,   -5.,   -6.],\n        [   1.,    0.,   74.,   -6.,   -8.,    3.]],\n\n       [[  -1.,    2.,    4.,   -1.,   -7.,    0.],\n        [  -1.,    1.,    6.,    5.,   -6.,    0.],\n        [   2.,    0.,   17.,    3.,   -4.,    0.],\n        ...,\n        [   1.,    0.,   25.,    0.,   -3.,   -2.],\n        [   0.,    0.,   22.,    2.,   -6.,    0.],\n        [   1.,    0.,   17.,    2.,   -4.,    0.]],\n\n       ...,\n\n       [[  -2.,    2.,   20.,    5.,   -6.,   -1.],\n        [  -3.,    1.,   18.,    4.,   -6.,    0.],\n        [  -2.,    2.,   20.,    5.,   -6.,   -1.],\n        ...,\n        [  -4.,    0.,   17.,    4.,   -9.,   -1.],\n        [  -4.,    0.,   32.,    4.,  -10.,   -1.],\n        [  -2.,    1.,   30.,    5.,   -5.,   -1.]],\n\n       [[ -39.,    3.,   11.,    5.,  -67.,   -2.],\n        [ -34.,   31.,   17.,  -60.,  -62.,  -16.],\n        [ -20.,   30.,   17.,  -51.,  -38.,   15.],\n        ...,\n        [   1.,   -1.,   17.,    5.,    0.,   -2.],\n        [   0.,    1.,   26.,    2.,   -2.,   -1.],\n        [  -5.,    0.,   20.,   -3.,  -11.,   -3.]],\n\n       [[ -25.,  -13., -199.,   18.,  -34.,  -10.],\n        [ -28.,  -20., -210.,   37.,  -59.,   -1.],\n        [ -45.,  -24., -559.,  122.,  -98.,  -25.],\n        ...,\n        [ -21.,    7.,   14.,  -17.,  -35.,    2.],\n        [ -13.,    2.,    9.,   -7.,  -23.,    2.],\n        [  -7.,   -2.,    9.,   -2.,  -14.,    2.]]], dtype=float32)>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mg:\\Arshad\\Amirkabir\\14002 Neural Networks\\Exercises\\Exercise 5\\Exercise_5_NN.ipynb Cell 46'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/Arshad/Amirkabir/14002%20Neural%20Networks/Exercises/Exercise%205/Exercise_5_NN.ipynb#ch0000075?line=0'>1</a>\u001b[0m elman_only_ensemble(X_test)\n",
      "File \u001b[1;32mc:\\Users\\GHD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/GHD/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/GHD/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> <a href='file:///c%3A/Users/GHD/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     <a href='file:///c%3A/Users/GHD/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/GHD/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\GHD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\input_spec.py:200\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/GHD/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/engine/input_spec.py?line=196'>197</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInputs to a layer should be tensors. Got: \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/GHD/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/engine/input_spec.py?line=198'>199</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(inputs) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(input_spec):\n\u001b[1;32m--> <a href='file:///c%3A/Users/GHD/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/engine/input_spec.py?line=199'>200</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mLayer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m expects \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(input_spec)\u001b[39m}\u001b[39;00m\u001b[39m input(s),\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/GHD/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/engine/input_spec.py?line=200'>201</a>\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m but it received \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(inputs)\u001b[39m}\u001b[39;00m\u001b[39m input tensors. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/GHD/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/engine/input_spec.py?line=201'>202</a>\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInputs received: \u001b[39m\u001b[39m{\u001b[39;00minputs\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/GHD/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/engine/input_spec.py?line=202'>203</a>\u001b[0m \u001b[39mfor\u001b[39;00m input_index, (x, spec) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mzip\u001b[39m(inputs, input_spec)):\n\u001b[0;32m    <a href='file:///c%3A/Users/GHD/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/engine/input_spec.py?line=203'>204</a>\u001b[0m   \u001b[39mif\u001b[39;00m spec \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Layer \"model_9\" expects 3 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor: shape=(93, 15, 6), dtype=float32, numpy=\narray([[[  46.,   29.,   59.,  -98.,  125.,  -16.],\n        [  19.,   18.,   96.,  -42.,   10.,   -6.],\n        [  27.,   23.,   93.,  -42.,   31.,   -9.],\n        ...,\n        [  -4.,   -7.,   84.,   -2.,  -16.,   -8.],\n        [  -3.,   -3.,   80.,   -7.,  -13.,   -1.],\n        [   0.,  -15.,   86.,   13.,  -11.,   -1.]],\n\n       [[  -4.,    3.,   76.,  -11.,  -16.,   -5.],\n        [  -2.,  -13.,   91.,   18.,  -12.,   -5.],\n        [   0.,    0.,   71.,   -9.,   -6.,   -4.],\n        ...,\n        [  -4.,   -1.,   83.,   -7.,  -18.,  -13.],\n        [   2.,   -9.,   83.,    7.,   -5.,   -6.],\n        [   1.,    0.,   74.,   -6.,   -8.,    3.]],\n\n       [[  -1.,    2.,    4.,   -1.,   -7.,    0.],\n        [  -1.,    1.,    6.,    5.,   -6.,    0.],\n        [   2.,    0.,   17.,    3.,   -4.,    0.],\n        ...,\n        [   1.,    0.,   25.,    0.,   -3.,   -2.],\n        [   0.,    0.,   22.,    2.,   -6.,    0.],\n        [   1.,    0.,   17.,    2.,   -4.,    0.]],\n\n       ...,\n\n       [[  -2.,    2.,   20.,    5.,   -6.,   -1.],\n        [  -3.,    1.,   18.,    4.,   -6.,    0.],\n        [  -2.,    2.,   20.,    5.,   -6.,   -1.],\n        ...,\n        [  -4.,    0.,   17.,    4.,   -9.,   -1.],\n        [  -4.,    0.,   32.,    4.,  -10.,   -1.],\n        [  -2.,    1.,   30.,    5.,   -5.,   -1.]],\n\n       [[ -39.,    3.,   11.,    5.,  -67.,   -2.],\n        [ -34.,   31.,   17.,  -60.,  -62.,  -16.],\n        [ -20.,   30.,   17.,  -51.,  -38.,   15.],\n        ...,\n        [   1.,   -1.,   17.,    5.,    0.,   -2.],\n        [   0.,    1.,   26.,    2.,   -2.,   -1.],\n        [  -5.,    0.,   20.,   -3.,  -11.,   -3.]],\n\n       [[ -25.,  -13., -199.,   18.,  -34.,  -10.],\n        [ -28.,  -20., -210.,   37.,  -59.,   -1.],\n        [ -45.,  -24., -559.,  122.,  -98.,  -25.],\n        ...,\n        [ -21.,    7.,   14.,  -17.,  -35.,    2.],\n        [ -13.,    2.,    9.,   -7.,  -23.,    2.],\n        [  -7.,   -2.,    9.,   -2.,  -14.,    2.]]], dtype=float32)>]"
     ]
    }
   ],
   "source": [
    "elman_only_ensemble(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jordan Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... \n",
      "Epoch 1/30\n",
      "323/323 [==============================] - 7s 7ms/step - loss: 0.5490 - acc: 0.7508 - val_loss: 0.4353 - val_acc: 0.7872\n",
      "Epoch 2/30\n",
      "323/323 [==============================] - 1s 4ms/step - loss: 0.4090 - acc: 0.8050 - val_loss: 0.3723 - val_acc: 0.8085\n",
      "Epoch 3/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.3569 - acc: 0.8328 - val_loss: 0.3263 - val_acc: 0.8191\n",
      "Epoch 4/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.3337 - acc: 0.8266 - val_loss: 0.3420 - val_acc: 0.7979\n",
      "Epoch 5/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.3396 - acc: 0.8251 - val_loss: 0.3311 - val_acc: 0.8085\n",
      "Epoch 6/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.3129 - acc: 0.8251 - val_loss: 0.2954 - val_acc: 0.8298\n",
      "Epoch 7/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.3175 - acc: 0.8297 - val_loss: 0.3251 - val_acc: 0.7872\n",
      "Epoch 8/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2961 - acc: 0.8653 - val_loss: 0.3112 - val_acc: 0.8723\n",
      "Epoch 9/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.3049 - acc: 0.8359 - val_loss: 0.2794 - val_acc: 0.8617\n",
      "Epoch 10/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2834 - acc: 0.8498 - val_loss: 0.2874 - val_acc: 0.8298\n",
      "Epoch 11/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2791 - acc: 0.8591 - val_loss: 0.2670 - val_acc: 0.8830\n",
      "Epoch 12/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2902 - acc: 0.8560 - val_loss: 0.3241 - val_acc: 0.8085\n",
      "Epoch 13/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2585 - acc: 0.8746 - val_loss: 0.2954 - val_acc: 0.8511\n",
      "Epoch 14/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.3162 - acc: 0.8529 - val_loss: 0.2755 - val_acc: 0.8723\n",
      "Epoch 15/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2771 - acc: 0.8529 - val_loss: 0.3256 - val_acc: 0.7979\n",
      "Epoch 16/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2608 - acc: 0.8560 - val_loss: 0.2484 - val_acc: 0.8617\n",
      "Epoch 17/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2534 - acc: 0.8808 - val_loss: 0.2464 - val_acc: 0.8936\n",
      "Epoch 18/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2325 - acc: 0.8824 - val_loss: 0.2154 - val_acc: 0.9149\n",
      "Epoch 19/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2259 - acc: 0.8715 - val_loss: 0.2153 - val_acc: 0.8936\n",
      "Epoch 20/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.1965 - acc: 0.9040 - val_loss: 0.2113 - val_acc: 0.8723\n",
      "Epoch 21/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2031 - acc: 0.8916 - val_loss: 0.2037 - val_acc: 0.9362\n",
      "Epoch 22/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.1810 - acc: 0.9319 - val_loss: 0.2136 - val_acc: 0.8936\n",
      "Epoch 23/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2645 - acc: 0.8793 - val_loss: 0.2853 - val_acc: 0.8298\n",
      "Epoch 24/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2174 - acc: 0.8622 - val_loss: 0.2692 - val_acc: 0.8617\n",
      "Epoch 25/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2223 - acc: 0.8824 - val_loss: 0.2921 - val_acc: 0.8404\n",
      "Epoch 26/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.1912 - acc: 0.8947 - val_loss: 0.1988 - val_acc: 0.8936\n",
      "Epoch 27/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.1650 - acc: 0.9087 - val_loss: 0.2031 - val_acc: 0.9043\n",
      "Epoch 28/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.1730 - acc: 0.9025 - val_loss: 0.1963 - val_acc: 0.8936\n",
      "Epoch 29/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.1683 - acc: 0.9334 - val_loss: 0.3033 - val_acc: 0.8723\n",
      "Epoch 30/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.1915 - acc: 0.9102 - val_loss: 0.2077 - val_acc: 0.8723\n"
     ]
    }
   ],
   "source": [
    "jordan_only_ensemble, jordan_only_ensemble_score = jordan_only_ensemble_experiment(\n",
    "    hidden_count_list=[10, 25, 50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 53, 54, 54, 54, 54, 54\n  y sizes: 323\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mg:\\Arshad\\Amirkabir\\14002 Neural Networks\\Exercises\\Exercise 5\\Exercise_5_NN.ipynb Cell 49'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/Arshad/Amirkabir/14002%20Neural%20Networks/Exercises/Exercise%205/Exercise_5_NN.ipynb#ch0000051?line=0'>1</a>\u001b[0m mixed_ensemble, mixed_ensemble_score \u001b[39m=\u001b[39m endgame_ensemble_experiment(\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Arshad/Amirkabir/14002%20Neural%20Networks/Exercises/Exercise%205/Exercise_5_NN.ipynb#ch0000051?line=1'>2</a>\u001b[0m     elman_hidden_count_list\u001b[39m=\u001b[39;49m[\u001b[39m10\u001b[39;49m, \u001b[39m25\u001b[39;49m, \u001b[39m50\u001b[39;49m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Arshad/Amirkabir/14002%20Neural%20Networks/Exercises/Exercise%205/Exercise_5_NN.ipynb#ch0000051?line=2'>3</a>\u001b[0m     jordan_hidden_count_list\u001b[39m=\u001b[39;49m[\u001b[39m10\u001b[39;49m, \u001b[39m25\u001b[39;49m, \u001b[39m50\u001b[39;49m])\n",
      "\u001b[1;32mg:\\Arshad\\Amirkabir\\14002 Neural Networks\\Exercises\\Exercise 5\\Exercise_5_NN.ipynb Cell 24'\u001b[0m in \u001b[0;36mendgame_ensemble_experiment\u001b[1;34m(elman_hidden_count_list, jordan_hidden_count_list)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Arshad/Amirkabir/14002%20Neural%20Networks/Exercises/Exercise%205/Exercise_5_NN.ipynb#ch0000067?line=29'>30</a>\u001b[0m     ensemble_model \u001b[39m=\u001b[39m create_ensemble_model(elman_submodels \u001b[39m+\u001b[39m jordan_submodels, active_index\u001b[39m=\u001b[39mi)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Arshad/Amirkabir/14002%20Neural%20Networks/Exercises/Exercise%205/Exercise_5_NN.ipynb#ch0000067?line=31'>32</a>\u001b[0m     \u001b[39m# Train the ensemble model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/Arshad/Amirkabir/14002%20Neural%20Networks/Exercises/Exercise%205/Exercise_5_NN.ipynb#ch0000067?line=32'>33</a>\u001b[0m     ensemble_model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Arshad/Amirkabir/14002%20Neural%20Networks/Exercises/Exercise%205/Exercise_5_NN.ipynb#ch0000067?line=33'>34</a>\u001b[0m         X_train_ensemble,\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Arshad/Amirkabir/14002%20Neural%20Networks/Exercises/Exercise%205/Exercise_5_NN.ipynb#ch0000067?line=34'>35</a>\u001b[0m         y_train,\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Arshad/Amirkabir/14002%20Neural%20Networks/Exercises/Exercise%205/Exercise_5_NN.ipynb#ch0000067?line=35'>36</a>\u001b[0m         batch_size\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Arshad/Amirkabir/14002%20Neural%20Networks/Exercises/Exercise%205/Exercise_5_NN.ipynb#ch0000067?line=36'>37</a>\u001b[0m         epochs\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Arshad/Amirkabir/14002%20Neural%20Networks/Exercises/Exercise%205/Exercise_5_NN.ipynb#ch0000067?line=37'>38</a>\u001b[0m         validation_data\u001b[39m=\u001b[39;49m(X_validation_ensemble, y_validation),\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Arshad/Amirkabir/14002%20Neural%20Networks/Exercises/Exercise%205/Exercise_5_NN.ipynb#ch0000067?line=38'>39</a>\u001b[0m         callbacks\u001b[39m=\u001b[39;49m[tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mTensorBoard(log_dir\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mlogs/endgame_ensemble-\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mformat(datetime\u001b[39m.\u001b[39;49mdatetime\u001b[39m.\u001b[39;49mnow()\u001b[39m.\u001b[39;49mstrftime(\u001b[39m\"\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mY\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mm\u001b[39;49m\u001b[39m%d\u001b[39;49;00m\u001b[39m-\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mH\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mM\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mS\u001b[39;49m\u001b[39m\"\u001b[39;49m)))])\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Arshad/Amirkabir/14002%20Neural%20Networks/Exercises/Exercise%205/Exercise_5_NN.ipynb#ch0000067?line=40'>41</a>\u001b[0m \u001b[39m# Report test accuracy\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Arshad/Amirkabir/14002%20Neural%20Networks/Exercises/Exercise%205/Exercise_5_NN.ipynb#ch0000067?line=41'>42</a>\u001b[0m \u001b[39m# evaluate_ensemble(ensemble_model, X_test, y_test)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Arshad/Amirkabir/14002%20Neural%20Networks/Exercises/Exercise%205/Exercise_5_NN.ipynb#ch0000067?line=42'>43</a>\u001b[0m test_accuracy \u001b[39m=\u001b[39m \u001b[39m0.6\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\GHD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/GHD/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/GHD/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> <a href='file:///c%3A/Users/GHD/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     <a href='file:///c%3A/Users/GHD/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/GHD/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\GHD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\data_adapter.py:1653\u001b[0m, in \u001b[0;36m_check_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/GHD/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/engine/data_adapter.py?line=1648'>1649</a>\u001b[0m   msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m  \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m sizes: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   <a href='file:///c%3A/Users/GHD/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/engine/data_adapter.py?line=1649'>1650</a>\u001b[0m       label, \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mstr\u001b[39m(i\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[0;32m   <a href='file:///c%3A/Users/GHD/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/engine/data_adapter.py?line=1650'>1651</a>\u001b[0m                        \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(single_data)))\n\u001b[0;32m   <a href='file:///c%3A/Users/GHD/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/engine/data_adapter.py?line=1651'>1652</a>\u001b[0m msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> <a href='file:///c%3A/Users/GHD/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/engine/data_adapter.py?line=1652'>1653</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 53, 54, 54, 54, 54, 54\n  y sizes: 323\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "mixed_ensemble, mixed_ensemble_score = endgame_ensemble_experiment(\n",
    "    elman_hidden_count_list=[10, 25, 50],\n",
    "    jordan_hidden_count_list=[10, 25, 50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tensorboard extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "# start tensorboard in the 'logs' directory\n",
    "%tensorboard --logdir=logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3858431499dcaaf4de29b8b352749eebe871787bd67cf3dfc1982c43a6256c9d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
