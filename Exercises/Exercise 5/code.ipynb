{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# To disable gpu warnings\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_label(l):\n",
    "    return int(l in {'ok', 'normal', 'moved', 'slightly_moved'})\n",
    "\n",
    "def instance_reader(file_path):\n",
    "    def _reader():\n",
    "        eof = False\n",
    "        with open(file_path) as f:\n",
    "            while True:\n",
    "                while True:\n",
    "                    _tmp = f.readline()\n",
    "                    if not _tmp:\n",
    "                        eof = True\n",
    "                        break\n",
    "                    elif _tmp != '\\n':\n",
    "                        break\n",
    "\n",
    "                if eof:\n",
    "                    break\n",
    "\n",
    "                label = None\n",
    "                instance = np.zeros((15, 6))\n",
    "\n",
    "                # GHD\n",
    "                label = determine_label(_tmp.strip())\n",
    "                \n",
    "                for i in range(15):\n",
    "                    content = f.readline()\n",
    "                    timeline = np.asarray(content[:-1].split('\\t')[1:]).astype(np.int64)\n",
    "                    instance[i] = np.asarray(timeline)\n",
    "\n",
    "                yield instance, label\n",
    "    return _reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "88it [00:00, 5176.77it/s]\n",
      "47it [00:00, 5542.25it/s]\n",
      "47it [00:00, 5891.58it/s]\n",
      "117it [00:00, 6173.22it/s]\n",
      "164it [00:00, 5667.60it/s]\n"
     ]
    }
   ],
   "source": [
    "data_directory = 'data'\n",
    "X = list()\n",
    "y = list()\n",
    "for datafile in os.listdir(data_directory):\n",
    "    ins_reader = instance_reader(os.path.join(data_directory, datafile))\n",
    "    for instance, label in tqdm(ins_reader()):\n",
    "        X.append(instance)\n",
    "        y.append(label)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "xtrain, xval, ytrain, yval = train_test_split(xtrain, ytrain, test_size=0.125, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12.,  8., 94., -9., 35., -1.])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elman Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElmanNeuralNetwork(tf.keras.Model):\n",
    "    def __init__(self, input_dim, hidden_units, feature_size, n_classes):\n",
    "        super(ElmanNeuralNetwork, self).__init__()\n",
    "        self.hidden_units = hidden_units\n",
    "        self.feature_size = feature_size\n",
    "        self.input_dim = input_dim\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        self.W = self.add_weight(shape=(self.hidden_units, self.feature_size), initializer='random_normal', trainable=True)\n",
    "        self.U = self.add_weight(shape=(self.hidden_units, self.hidden_units), initializer='random_normal', trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.hidden_units,), initializer='random_normal', trainable=True)\n",
    "\n",
    "        self.W_y = self.add_weight(shape=(self.n_classes, self.hidden_units), initializer='random_normal', trainable=True)\n",
    "        self.b_y = self.add_weight(shape=(self.n_classes,), initializer='random_normal', trainable=True)\n",
    "\n",
    "    def call(self, x):\n",
    "        state_t = tf.zeros(self.hidden_units)\n",
    "        for i in range(self.input_dim):\n",
    "            state_t = tf.keras.activations.tanh(tf.matmul(self.W, tf.reshape(x[0][i], (self.feature_size, 1))) + tf.matmul(self.U, tf.reshape(state_t, (self.hidden_units,1))) + tf.reshape(self.b, (self.hidden_units, 1)))\n",
    "\n",
    "        y = tf.keras.activations.tanh(tf.matmul(self.W_y, tf.reshape(state_t, (self.hidden_units,1))) + tf.reshape(self.b_y, (self.n_classes,1)))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "323/323 [==============================] - 2s 4ms/step - loss: 2.8160 - acc: 0.6966 - val_loss: 2.6689 - val_acc: 0.7234\n",
      "Epoch 2/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.7236 - acc: 0.7214 - val_loss: 2.6619 - val_acc: 0.7128\n",
      "Epoch 3/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.7106 - acc: 0.7368 - val_loss: 2.6580 - val_acc: 0.7234\n",
      "Epoch 4/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.6988 - acc: 0.7508 - val_loss: 2.6527 - val_acc: 0.7340\n",
      "Epoch 5/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.6929 - acc: 0.7523 - val_loss: 2.6460 - val_acc: 0.7447\n",
      "Epoch 6/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.6917 - acc: 0.7539 - val_loss: 2.6460 - val_acc: 0.7340\n",
      "Epoch 7/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.6852 - acc: 0.7585 - val_loss: 2.6550 - val_acc: 0.7128\n",
      "Epoch 8/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 2.6828 - acc: 0.7554 - val_loss: 2.6527 - val_acc: 0.7234\n",
      "Epoch 9/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.6767 - acc: 0.7570 - val_loss: 2.6641 - val_acc: 0.7234\n",
      "Epoch 10/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.6783 - acc: 0.7523 - val_loss: 2.6533 - val_acc: 0.7340\n",
      "Epoch 11/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.6740 - acc: 0.7523 - val_loss: 2.6487 - val_acc: 0.7021\n",
      "Epoch 12/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.6673 - acc: 0.7647 - val_loss: 2.6575 - val_acc: 0.7234\n",
      "Epoch 13/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.6667 - acc: 0.7632 - val_loss: 2.6450 - val_acc: 0.6915\n",
      "Epoch 14/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.6799 - acc: 0.7709 - val_loss: 2.6799 - val_acc: 0.7234\n",
      "Epoch 15/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.6631 - acc: 0.7632 - val_loss: 2.6330 - val_acc: 0.7234\n",
      "Epoch 16/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.6578 - acc: 0.7663 - val_loss: 2.6911 - val_acc: 0.7340\n",
      "Epoch 17/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.6558 - acc: 0.7724 - val_loss: 2.6446 - val_acc: 0.7128\n",
      "Epoch 18/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.6553 - acc: 0.7647 - val_loss: 2.6521 - val_acc: 0.6915\n",
      "Epoch 19/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.6488 - acc: 0.7693 - val_loss: 2.6474 - val_acc: 0.7234\n",
      "Epoch 20/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.6517 - acc: 0.7755 - val_loss: 2.6393 - val_acc: 0.7234\n",
      "Epoch 21/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.6467 - acc: 0.7724 - val_loss: 2.8259 - val_acc: 0.6915\n",
      "Epoch 22/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.6642 - acc: 0.7817 - val_loss: 2.6707 - val_acc: 0.7128\n",
      "Epoch 23/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.6701 - acc: 0.7616 - val_loss: 2.6882 - val_acc: 0.7021\n",
      "Epoch 24/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.6672 - acc: 0.7570 - val_loss: 2.6928 - val_acc: 0.7021\n",
      "Epoch 25/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.6601 - acc: 0.7632 - val_loss: 2.6353 - val_acc: 0.7234\n",
      "Epoch 26/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.6504 - acc: 0.7601 - val_loss: 2.6832 - val_acc: 0.6915\n",
      "Epoch 27/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.6426 - acc: 0.7724 - val_loss: 2.6898 - val_acc: 0.6915\n",
      "Epoch 28/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.6406 - acc: 0.7771 - val_loss: 2.9527 - val_acc: 0.7021\n",
      "Epoch 29/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.6619 - acc: 0.7817 - val_loss: 2.8207 - val_acc: 0.6915\n",
      "Epoch 30/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 2.6389 - acc: 0.7864 - val_loss: 2.8006 - val_acc: 0.6915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f17cb78be0>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "elman_nn = ElmanNeuralNetwork(input_dim=15, hidden_units=10, feature_size=6, n_classes=2)\n",
    "\n",
    "elman_nn.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['acc'])\n",
    "elman_nn.fit(\n",
    "    xtrain,\n",
    "    ytrain,\n",
    "    batch_size=1,\n",
    "    epochs=30,\n",
    "    validation_data=(xval, yval),\n",
    "    callbacks=[tf.keras.callbacks.TensorBoard(log_dir='logs/datetime-elman-{}'.format(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 11948), started 0:00:46 ago. (Use '!kill 11948' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9fbb4f7f90a8ff4\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9fbb4f7f90a8ff4\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load tensorboard\n",
    "%tensorboard --logdir=logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jordan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JordanNeuralNetwork(tf.keras.Model):\n",
    "    def __init__(self, input_dim, hidden_units, feature_size, n_classes):\n",
    "        super(JordanNeuralNetwork, self).__init__()\n",
    "        self.hidden_units = hidden_units\n",
    "        self.feature_size = feature_size\n",
    "        self.input_dim = input_dim\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        self.W = self.add_weight(shape=(self.hidden_units, self.feature_size), initializer='random_normal', trainable=True)\n",
    "        self.U = self.add_weight(shape=(self.hidden_units, self.hidden_units), initializer='random_normal', trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.hidden_units,), initializer='random_normal', trainable=True)\n",
    "\n",
    "        self.W_y_intermediate = self.add_weight(shape=(self.hidden_units, self.hidden_units), initializer='random_normal', trainable=True)\n",
    "        self.b_y_intermediate = self.add_weight(shape=(self.hidden_units,), initializer='random_normal', trainable=True)\n",
    "\n",
    "        self.W_y = self.add_weight(shape=(self.n_classes, self.hidden_units), initializer='random_normal', trainable=True)\n",
    "        self.b_y = self.add_weight(shape=(self.n_classes,), initializer='random_normal', trainable=True)\n",
    "\n",
    "    def call(self, x):\n",
    "        state_t = tf.zeros(self.hidden_units)\n",
    "        for i in range(self.input_dim):\n",
    "            hidden = tf.keras.activations.tanh(tf.matmul(self.W, tf.reshape(x[0][i], (self.feature_size, 1))) + tf.matmul(self.U, tf.reshape(state_t, (self.hidden_units,1))) + tf.reshape(self.b, (self.hidden_units, 1)))\n",
    "            y_intermediate = tf.keras.activations.tanh(tf.matmul(self.W_y_intermediate, tf.reshape(hidden, (self.hidden_units,1))) + tf.reshape(self.b_y_intermediate, (self.hidden_units,1)))\n",
    "            state_t = y_intermediate\n",
    "        y = tf.keras.activations.tanh(tf.matmul(self.W_y, tf.reshape(state_t, (self.hidden_units,1))) + tf.reshape(self.b_y, (self.n_classes,1)))\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "323/323 [==============================] - 3s 5ms/step - loss: 0.5916 - acc: 0.6672 - val_loss: 0.4042 - val_acc: 0.7766\n",
      "Epoch 2/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.3818 - acc: 0.7833 - val_loss: 0.3907 - val_acc: 0.8085\n",
      "Epoch 3/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3659 - acc: 0.7910 - val_loss: 0.4325 - val_acc: 0.7447\n",
      "Epoch 4/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3528 - acc: 0.8111 - val_loss: 0.3962 - val_acc: 0.7021\n",
      "Epoch 5/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3385 - acc: 0.8111 - val_loss: 0.3859 - val_acc: 0.7872\n",
      "Epoch 6/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3478 - acc: 0.8034 - val_loss: 0.3699 - val_acc: 0.7872\n",
      "Epoch 7/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3276 - acc: 0.8282 - val_loss: 0.3734 - val_acc: 0.7447\n",
      "Epoch 8/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3162 - acc: 0.8467 - val_loss: 0.3816 - val_acc: 0.7872\n",
      "Epoch 9/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3022 - acc: 0.8251 - val_loss: 0.3665 - val_acc: 0.7447\n",
      "Epoch 10/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2906 - acc: 0.8421 - val_loss: 0.3501 - val_acc: 0.7447\n",
      "Epoch 11/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2844 - acc: 0.8483 - val_loss: 0.3737 - val_acc: 0.7447\n",
      "Epoch 12/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2805 - acc: 0.8328 - val_loss: 0.3691 - val_acc: 0.7447\n",
      "Epoch 13/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.4519 - acc: 0.8545 - val_loss: 0.3680 - val_acc: 0.8085\n",
      "Epoch 14/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2728 - acc: 0.8467 - val_loss: 0.6834 - val_acc: 0.7660\n",
      "Epoch 15/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2977 - acc: 0.8514 - val_loss: 0.6639 - val_acc: 0.7660\n",
      "Epoch 16/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3033 - acc: 0.8452 - val_loss: 0.4178 - val_acc: 0.7447\n",
      "Epoch 17/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2994 - acc: 0.8390 - val_loss: 0.3611 - val_acc: 0.7447\n",
      "Epoch 18/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2841 - acc: 0.8591 - val_loss: 0.6856 - val_acc: 0.7660\n",
      "Epoch 19/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3769 - acc: 0.8576 - val_loss: 0.9631 - val_acc: 0.7447\n",
      "Epoch 20/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3271 - acc: 0.8514 - val_loss: 0.9648 - val_acc: 0.7447\n",
      "Epoch 21/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3904 - acc: 0.8591 - val_loss: 0.3190 - val_acc: 0.8085\n",
      "Epoch 22/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.4395 - acc: 0.8514 - val_loss: 0.9570 - val_acc: 0.7660\n",
      "Epoch 23/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.4133 - acc: 0.8514 - val_loss: 0.9622 - val_acc: 0.7660\n",
      "Epoch 24/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3552 - acc: 0.8591 - val_loss: 0.6594 - val_acc: 0.7872\n",
      "Epoch 25/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3427 - acc: 0.8638 - val_loss: 0.9557 - val_acc: 0.7660\n",
      "Epoch 26/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3452 - acc: 0.8684 - val_loss: 0.9836 - val_acc: 0.7447\n",
      "Epoch 27/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3388 - acc: 0.8622 - val_loss: 0.9293 - val_acc: 0.7872\n",
      "Epoch 28/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3370 - acc: 0.8390 - val_loss: 0.3209 - val_acc: 0.8298\n",
      "Epoch 29/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2884 - acc: 0.8328 - val_loss: 0.3167 - val_acc: 0.7447\n",
      "Epoch 30/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2750 - acc: 0.8359 - val_loss: 0.3580 - val_acc: 0.7979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f105bdb970>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "jordan_nn = JordanNeuralNetwork(input_dim=15, hidden_units=10, feature_size=6, n_classes=2)\n",
    "\n",
    "jordan_nn.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['acc'])\n",
    "jordan_nn.fit(\n",
    "    xtrain,\n",
    "    ytrain,\n",
    "    batch_size=1,\n",
    "    epochs=30,\n",
    "    validation_data=(xval, yval),\n",
    "    callbacks=[tf.keras.callbacks.TensorBoard(log_dir='logs/datetime-jordan-{}'.format(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "323/323 [==============================] - 3s 5ms/step - loss: 0.7514 - acc: 0.6827 - val_loss: 0.4031 - val_acc: 0.7128\n",
      "Epoch 2/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.4000 - acc: 0.7260 - val_loss: 0.3797 - val_acc: 0.7553\n",
      "Epoch 3/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.3702 - acc: 0.7864 - val_loss: 0.3920 - val_acc: 0.7447\n",
      "Epoch 4/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3517 - acc: 0.8142 - val_loss: 0.3884 - val_acc: 0.7234\n",
      "Epoch 5/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3414 - acc: 0.8328 - val_loss: 0.3839 - val_acc: 0.7553\n",
      "Epoch 6/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3275 - acc: 0.8328 - val_loss: 0.3780 - val_acc: 0.7340\n",
      "Epoch 7/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.3228 - acc: 0.8313 - val_loss: 0.3866 - val_acc: 0.7128\n",
      "Epoch 8/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3357 - acc: 0.8467 - val_loss: 0.5710 - val_acc: 0.7553\n",
      "Epoch 9/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.3175 - acc: 0.8375 - val_loss: 0.3730 - val_acc: 0.7660\n",
      "Epoch 10/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3039 - acc: 0.8467 - val_loss: 0.3784 - val_acc: 0.7660\n",
      "Epoch 11/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3005 - acc: 0.8498 - val_loss: 0.3838 - val_acc: 0.7340\n",
      "Epoch 12/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2949 - acc: 0.8452 - val_loss: 0.3893 - val_acc: 0.7447\n",
      "Epoch 13/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2878 - acc: 0.8467 - val_loss: 0.3821 - val_acc: 0.7234\n",
      "Epoch 14/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2891 - acc: 0.8591 - val_loss: 0.4171 - val_acc: 0.7660\n",
      "Epoch 15/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2941 - acc: 0.8313 - val_loss: 0.3970 - val_acc: 0.7447\n",
      "Epoch 16/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2797 - acc: 0.8375 - val_loss: 0.3927 - val_acc: 0.7340\n",
      "Epoch 17/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2789 - acc: 0.8545 - val_loss: 0.4063 - val_acc: 0.7447\n",
      "Epoch 18/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2710 - acc: 0.8545 - val_loss: 0.3965 - val_acc: 0.7234\n",
      "Epoch 19/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2728 - acc: 0.8545 - val_loss: 0.4163 - val_acc: 0.7660\n",
      "Epoch 20/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2607 - acc: 0.8622 - val_loss: 0.4169 - val_acc: 0.7660\n",
      "Epoch 21/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2630 - acc: 0.8591 - val_loss: 0.4453 - val_acc: 0.7447\n",
      "Epoch 22/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2504 - acc: 0.8622 - val_loss: 0.3982 - val_acc: 0.7766\n",
      "Epoch 23/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2547 - acc: 0.8684 - val_loss: 0.4377 - val_acc: 0.7021\n",
      "Epoch 24/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3496 - acc: 0.8715 - val_loss: 0.6615 - val_acc: 0.7128\n",
      "Epoch 25/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2408 - acc: 0.8669 - val_loss: 0.6315 - val_acc: 0.7340\n",
      "Epoch 26/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2351 - acc: 0.8793 - val_loss: 0.7302 - val_acc: 0.7660\n",
      "Epoch 27/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2425 - acc: 0.8576 - val_loss: 0.4276 - val_acc: 0.7447\n",
      "Epoch 28/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2240 - acc: 0.8746 - val_loss: 0.4791 - val_acc: 0.7340\n",
      "Epoch 29/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2219 - acc: 0.8824 - val_loss: 0.5033 - val_acc: 0.7234\n",
      "Epoch 30/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2216 - acc: 0.8994 - val_loss: 0.4587 - val_acc: 0.7660\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f1080cb430>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elman_nn1 = ElmanNeuralNetwork(input_dim=15, hidden_units=10, feature_size=6, n_classes=2)\n",
    "\n",
    "elman_nn1.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['acc'])\n",
    "elman_nn1.fit(\n",
    "    xtrain,\n",
    "    ytrain,\n",
    "    batch_size=1,\n",
    "    epochs=30,\n",
    "    validation_data=(xval, yval),\n",
    "    callbacks=[tf.keras.callbacks.TensorBoard(log_dir='logs/datetime-elman1-{}'.format(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "323/323 [==============================] - 3s 5ms/step - loss: 0.9278 - acc: 0.6904 - val_loss: 0.3818 - val_acc: 0.8085\n",
      "Epoch 2/30\n",
      "323/323 [==============================] - 1s 4ms/step - loss: 0.3574 - acc: 0.7926 - val_loss: 0.3897 - val_acc: 0.8085\n",
      "Epoch 3/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3387 - acc: 0.8266 - val_loss: 0.3593 - val_acc: 0.8085\n",
      "Epoch 4/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3138 - acc: 0.8328 - val_loss: 0.3578 - val_acc: 0.7660\n",
      "Epoch 5/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2963 - acc: 0.8297 - val_loss: 0.3595 - val_acc: 0.7447\n",
      "Epoch 6/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2889 - acc: 0.8545 - val_loss: 0.4593 - val_acc: 0.7872\n",
      "Epoch 7/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2829 - acc: 0.8359 - val_loss: 0.3575 - val_acc: 0.8085\n",
      "Epoch 8/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2654 - acc: 0.8576 - val_loss: 0.3580 - val_acc: 0.8085\n",
      "Epoch 9/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2709 - acc: 0.8514 - val_loss: 0.3489 - val_acc: 0.7447\n",
      "Epoch 10/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2594 - acc: 0.8885 - val_loss: 0.3369 - val_acc: 0.7660\n",
      "Epoch 11/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2507 - acc: 0.8669 - val_loss: 0.3689 - val_acc: 0.7660\n",
      "Epoch 12/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3932 - acc: 0.8576 - val_loss: 0.3595 - val_acc: 0.7234\n",
      "Epoch 13/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2837 - acc: 0.8824 - val_loss: 0.3892 - val_acc: 0.7234\n",
      "Epoch 14/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2375 - acc: 0.8638 - val_loss: 0.3896 - val_acc: 0.7234\n",
      "Epoch 15/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2352 - acc: 0.8607 - val_loss: 0.7148 - val_acc: 0.7234\n",
      "Epoch 16/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2829 - acc: 0.8669 - val_loss: 0.4230 - val_acc: 0.7447\n",
      "Epoch 17/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2379 - acc: 0.8731 - val_loss: 0.3486 - val_acc: 0.8085\n",
      "Epoch 18/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2305 - acc: 0.8731 - val_loss: 0.3601 - val_acc: 0.7872\n",
      "Epoch 19/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2335 - acc: 0.9009 - val_loss: 0.4374 - val_acc: 0.7660\n",
      "Epoch 20/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2179 - acc: 0.8947 - val_loss: 0.6891 - val_acc: 0.7021\n",
      "Epoch 21/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2112 - acc: 0.9133 - val_loss: 0.4208 - val_acc: 0.7660\n",
      "Epoch 22/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2061 - acc: 0.8885 - val_loss: 0.3786 - val_acc: 0.7660\n",
      "Epoch 23/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2068 - acc: 0.8854 - val_loss: 0.3744 - val_acc: 0.7234\n",
      "Epoch 24/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2030 - acc: 0.9040 - val_loss: 0.3649 - val_acc: 0.7660\n",
      "Epoch 25/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2073 - acc: 0.8978 - val_loss: 0.4555 - val_acc: 0.7660\n",
      "Epoch 26/30\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2028 - acc: 0.8978 - val_loss: 0.4014 - val_acc: 0.7021\n",
      "Epoch 27/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2219 - acc: 0.8854 - val_loss: 0.4284 - val_acc: 0.7447\n",
      "Epoch 28/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2462 - acc: 0.8700 - val_loss: 0.3972 - val_acc: 0.7660\n",
      "Epoch 29/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2545 - acc: 0.8854 - val_loss: 0.4588 - val_acc: 0.7234\n",
      "Epoch 30/30\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.1978 - acc: 0.9040 - val_loss: 0.9790 - val_acc: 0.7234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f1100946d0>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elman_nn2 = ElmanNeuralNetwork(input_dim=15, hidden_units=20, feature_size=6, n_classes=1)\n",
    "elman_nn2.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['acc'])\n",
    "elman_nn2.fit(\n",
    "    xtrain,\n",
    "    ytrain,\n",
    "    batch_size=1,\n",
    "    epochs=30,\n",
    "    validation_data=(xval, yval),\n",
    "    callbacks=[tf.keras.callbacks.TensorBoard(log_dir='logs/datetime-elman2-{}'.format(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "id=6\n",
    "print(ytrain[id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[0.95896643],\n",
       "       [0.9612518 ]], dtype=float32)>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elman_nn1(xtrain[np.newaxis,id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.9331546]], dtype=float32)>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elman_nn2(xtrain[np.newaxis,id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal\n",
      "TAAAAB\t-1\t-1\t63\t-3\t-1\t0\n",
      "TAAAAB\t0\t0\t62\t-3\t-1\t0\n",
      "TAAAAB\t-1\t-1\t61\t-3\t0\t0\n",
      "TAAAAB\t-1\t-1\t63\t-2\t-1\t0\n",
      "TAAAAB\t-1\t-1\t63\t-3\t-1\t0\n",
      "TAAAAB\t-1\t-1\t63\t-3\t-1\t0\n",
      "TAAAAB\t-1\t-1\t63\t-3\t0\t0\n",
      "TAAAAB\t-1\t-1\t63\t-3\t-1\t0\n",
      "TAAAAB\t-1\t-1\t63\t-3\t-1\t0\n",
      "TAAAAB\t-1\t-1\t61\t-3\t0\t0\n",
      "TAAAAB\t-1\t-1\t61\t-3\t0\t0\n",
      "TAAAAB\t-1\t-1\t64\t-3\t-1\t0\n",
      "TAAAAB\t-1\t-1\t64\t-3\t-1\t0\n",
      "TAAAAB\t-1\t-1\t60\t-3\t0\t0\n",
      "TAAAAB\t-1\t0\t64\t-2\t-1\t0\n",
      "\n",
      "NNNNNN\n",
      "normal\n",
      "TAAAAB\t-1\t-1\t63\t-2\t-1\t0\n",
      "TAAAAB\t-1\t-1\t63\t-3\t-1\t0\n",
      "TAAAAB\t-1\t-1\t61\t-3\t0\t0\n",
      "TAAAAB\t0\t-4\t63\t1\t0\t0\n",
      "TAAAAB\t0\t-1\t59\t-2\t0\t-1\n",
      "TAAAAB\t-3\t3\t57\t-8\t-3\t-1\n",
      "TAAAAB\t-1\t3\t70\t-10\t-2\t-1\n",
      "TAAAAB\t0\t-3\t61\t0\t0\t0\n",
      "TAAAAB\t0\t-2\t53\t-1\t-2\t0\n",
      "TAAAAB\t0\t-3\t66\t1\t4\t0\n",
      "TAAAAB\t-3\t3\t58\t-10\t-5\t0\n",
      "TAAAAB\t-1\t-1\t66\t-4\t-2\t0\n",
      "TAAAAB\t-1\t-2\t67\t-3\t-1\t0\n",
      "TAAAAB\t0\t1\t66\t-6\t-3\t-1\n",
      "TAAAAB\t-1\t-1\t59\t-3\t-4\t0\n",
      "NNNNNN\n",
      "NNNNNN\n",
      "normal\n",
      "TAAAAB\t-1\t0\t57\t-5\t-3\t0\n",
      "TAAAAB\t0\t-3\t63\t-1\t0\t0\n",
      "TAAAAB\t-1\t1\t51\t-4\t-1\t-1\n"
     ]
    }
   ],
   "source": [
    "segments = []\n",
    "labels = []\n",
    "label_index = []\n",
    "i = 0\n",
    "with open('data/lp1.data', 'r') as f:\n",
    "    prev_line_hoo = False\n",
    "    for line in f.readlines()[:40]:\n",
    "        if line.startswith(\"\\n\"):\n",
    "            if prev_line_hoo:\n",
    "                print(\"NNNNNN\", end=\"\")\n",
    "                # segments.append(\"HOOOOOO\")\n",
    "            prev_line_hoo = True\n",
    "        elif line.startswith(\"\\t\"):\n",
    "            print(\"TAAAAB\", end=\"\")\n",
    "            segments.append(list(map(int, line.split())))\n",
    "        elif line == \"\\n\":\n",
    "            print(\"FFFFFF\")\n",
    "            \n",
    "        else:\n",
    "            labels.append(line)\n",
    "            label_index.append(i)\n",
    "        print(line, end=\"\")\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = []\n",
    "labels = []\n",
    "label_index = []\n",
    "i = 0\n",
    "with open('data/lp1.data', 'r') as f:\n",
    "    prev_line_hoo = False\n",
    "    for line in f.readlines()[:100]:\n",
    "        if line.startswith(\"\\n\"):\n",
    "            pass\n",
    "        elif line.startswith(\"\\t\"):\n",
    "            segments.append(list(map(int, line.split())))\n",
    "        elif line == \"\\n\":\n",
    "            pass\n",
    "        else:\n",
    "            labels.append(line)\n",
    "            label_index.append(i)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 18, 36, 54, 72, 90]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "normal\n",
      "-1 -1 63 -3 -1 0\n",
      "0 0 62 -3 -1 0\n",
      "-1 -1 61 -3 0 0\n",
      "-1 -1 63 -2 -1 0\n",
      "-1 -1 63 -3 -1 0\n",
      "-1 -1 63 -3 -1 0\n",
      "-1 -1 63 -3 0 0\n",
      "-1 -1 63 -3 -1 0\n",
      "-1 -1 63 -3 -1 0\n",
      "-1 -1 61 -3 0 0\n",
      "-1 -1 61 -3 0 0\n",
      "-1 -1 64 -3 -1 0\n",
      "-1 -1 64 -3 -1 0\n",
      "-1 -1 60 -3 0 0\n",
      "-1 0 64 -2 -1 0\n",
      "-1 -1 63 -2 -1 0\n",
      "-1 -1 63 -3 -1 0\n",
      "-1 -1 61 -3 0 0\n",
      "\n",
      "normal\n",
      "0 -4 63 1 0 0\n",
      "0 -1 59 -2 0 -1\n",
      "-3 3 57 -8 -3 -1\n",
      "-1 3 70 -10 -2 -1\n",
      "0 -3 61 0 0 0\n",
      "0 -2 53 -1 -2 0\n",
      "0 -3 66 1 4 0\n",
      "-3 3 58 -10 -5 0\n",
      "-1 -1 66 -4 -2 0\n",
      "-1 -2 67 -3 -1 0\n",
      "0 1 66 -6 -3 -1\n",
      "-1 -1 59 -3 -4 0\n",
      "-1 0 57 -5 -3 0\n",
      "0 -3 63 -1 0 0\n",
      "-1 1 51 -4 -1 -1\n",
      "-1 -2 68 -2 -2 0\n",
      "-1 -1 65 -6 1 0\n",
      "0 0 61 -5 -2 0\n",
      "\n",
      "normal\n",
      "-1 1 61 -6 0 -1\n",
      "0 -3 57 3 -4 0\n",
      "-1 -1 59 -4 -4 0\n",
      "1 -3 65 -1 1 0\n",
      "-1 2 64 -7 -2 0\n",
      "-1 1 66 -7 -3 -1\n",
      "-1 0 61 -5 -5 0\n",
      "-1 0 65 -6 -2 -1\n",
      "-1 0 54 -4 -3 0\n",
      "0 -1 59 -2 -1 -1\n",
      "0 -3 61 -1 2 0\n",
      "-2 1 56 -6 -3 0\n",
      "1 -3 64 -1 4 0\n",
      "-1 1 62 -7 1 -1\n",
      "-1 0 60 -9 -5 -1\n",
      "1 1 56 -5 0 0\n",
      "1 -1 66 -4 2 1\n",
      "-2 5 64 -15 -2 0\n",
      "\n",
      "normal\n",
      "-1 2 58 -8 -4 0\n",
      "0 1 70 -9 -2 -1\n",
      "-1 1 64 -8 -6 -1\n",
      "0 -1 67 -6 0 -1\n",
      "0 -2 63 -4 0 0\n",
      "-1 1 63 -8 -2 0\n",
      "0 -2 65 -4 -2 0\n",
      "-1 -2 56 -5 -3 0\n",
      "0 0 58 -9 -1 0\n",
      "-1 -1 56 -5 -3 0\n",
      "-2 3 57 -12 -4 -1\n",
      "-1 -2 65 -5 -2 0\n",
      "-1 2 56 -9 -5 0\n",
      "2 -2 60 -2 3 1\n",
      "0 1 67 -9 -2 1\n",
      "-1 2 60 -10 -5 0\n",
      "0 -3 63 -3 -1 0\n",
      "-1 -1 73 -8 -5 0\n",
      "\n",
      "normal\n",
      "-1 0 57 -7 -4 -1\n",
      "-1 0 59 -8 -4 -1\n",
      "-1 1 57 -9 -4 -1\n",
      "-1 2 57 -10 -3 0\n",
      "-2 3 60 -12 -4 -1\n",
      "-1 2 63 -12 -6 1\n",
      "1 3 62 -11 0 0\n",
      "-3 2 56 -9 -4 0\n",
      "0 1 58 -8 -1 -1\n",
      "-1 3 57 -11 -4 0\n",
      "-2 3 61 -10 -5 0\n",
      "-3 3 60 -11 -4 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(segments)):\n",
    "    if i in label_index:\n",
    "        print()\n",
    "        print(labels[label_index.index(i)][:-1])\n",
    "        print(\" \".join(list(map(str, segments[i]))))\n",
    "    else:\n",
    "        print(\" \".join(list(map(str, segments[i]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3858431499dcaaf4de29b8b352749eebe871787bd67cf3dfc1982c43a6256c9d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
